<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>hadoop集群的安装与配置 | 隶笔难书</title>
<meta name=keywords content="Hadoop"><meta name=description content="hadoop集群的安装与配置"><meta name=author content><link rel=canonical href=https://waite.wang/posts/bigdata/hadoop-group-install-and-config/><link crossorigin=anonymous href=/assets/css/stylesheet.3d97af64455e262976bc8963ce1a2382d14e8c2788745b1deedf23a8e2ebd65c.css integrity="sha256-PZevZEVeJil2vIljzhojgtFOjCeIdFsd7t8jqOLr1lw=" rel="preload stylesheet" as=style><link rel=icon href=https://waite.wang/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://waite.wang/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://waite.wang/favicon-32x32.png><link rel=apple-touch-icon href=https://waite.wang/apple-touch-icon.png><link rel=mask-icon href=https://waite.wang/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-cn href=https://waite.wang/posts/bigdata/hadoop-group-install-and-config/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://waite.wang/posts/bigdata/hadoop-group-install-and-config/"><meta property="og:site_name" content="隶笔难书"><meta property="og:title" content="hadoop集群的安装与配置"><meta property="og:description" content="hadoop集群的安装与配置"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-10T16:04:23+08:00"><meta property="article:modified_time" content="2022-12-10T16:04:23+08:00"><meta property="article:tag" content="Hadoop"><meta name=twitter:card content="summary"><meta name=twitter:title content="hadoop集群的安装与配置"><meta name=twitter:description content="hadoop集群的安装与配置"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://waite.wang/posts/"},{"@type":"ListItem","position":2,"name":"hadoop集群的安装与配置","item":"https://waite.wang/posts/bigdata/hadoop-group-install-and-config/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"hadoop集群的安装与配置","name":"hadoop集群的安装与配置","description":"hadoop集群的安装与配置","keywords":["Hadoop"],"articleBody":"Hadoop基础 1 、实验目的 通过本节实验的学习，同学们可以掌握Hadoop集群环境部署与配置。本实验完成后，要求学生掌握以下内容：\n掌握集群所有节点之间SSH免密登录配置方式；\n掌握NTP服务配置，实现节点间的时间同步；\n掌握ZooKeeper集群的搭建方式；\n掌握Hadoop集群的搭建配置流程；\n理解Hadoop集群的高可用（HA）原理，并掌握Hadoop集群的高可用（HA）配置方法。\n2、实验原理 需要按照以下流程，在Linux上进行Hadoop集群的安装部署：\n主机名配置：在大型的Hadoop集群中，往往由成百上千个节点组成，如果通过IP地址对不同节点进行管理，那么集群维护的工作量将会十分繁重，因此在工程环境中，常常通过对每个节点设置唯一的主机名，从而实现对节点进行管理。\nSSH（安全外壳协议）免密码登录配置：推荐安装OpenSSH。Hadoop需要通过SSH来启动Slave列表中各台主机的守护进程，因此SSH也是必须安装的。\n安装配置JDK1.7（或更高版本）：Hadoop是用Java编写的程序，Hadoop的编译及MapReduce的运行都需要使用JDK，因此在安装Hadoop前，必须安装JDK1.7或更高版本。\nNTP服务配置：本实验需要在实现Hadoop集群搭建的同时，并进行高可用性（HA）的配置，因此需要通过ZooKeeper来对集群中的节点进行协调，而ZooKeeper需要保证节点间的时钟相互一致，因此需要在集群中配置NTP服务。\nSElinux安全配置：CentOS默认启用了SElinux，在网络服务方面权限要求比较严格，因此需要对SElinux安全配置进行更改。\nZooKeeper集群搭建：高可用性（HA）Hadoop集群的搭建需要依赖于ZooKeeper来对集群中的节点进行协调，因此需要进行ZooKeeper集群搭建。\nHadoop核心配置。Hadoop的稳定运行需要依赖于其核心配置文件，因此当上述准备工作就绪后，我们便需要着重进行配置文件编写来实现Hadoop的可靠运行。\n我们需要在节点1、节点2、节点3中进行高可用Hadoop集群环境的部署。各个节点所部署的服务如下所示：\n节点1 节点2 节点3 NameNode StandBy ResourceManager StandBy DFSZKFailoverController DFSZKFailoverController DataNode DataNode DataNode NodeManager NodeManager NodeManager JournalNode JournalNode JournalNode 1 集群节点基本配置 步骤1. 节点IP地址查询 在节点1、2、3中通过下面的命令查询节点IP地址： ifconfig 命令运行后的返回结果如下所示 (每台虚拟机的IP地址都是不同的，因此需要以实际地址信息为准）：\n[root@CentOS6 ~]# ifconfig eth6 Link encap:Ethernet HWaddr 02:00:1E:79:09:04 inet addr:10.1.1.4 Bcast:10.1.1.255 Mask:255.255.255.0 inet6 addr: fe80::1eff:fe79:904/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:20832 errors:0 dropped:0 overruns:0 frame:0 TX packets:13052 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:31392026 (29.9 MiB) TX bytes:929956 (908.1 KiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:12 errors:0 dropped:0 overruns:0 frame:0 TX packets:12 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:720 (720.0 b) TX bytes:720 (720.0 b) [root@CentOS6 ~]# 需要记录三个节点的IP地址，在后文中我们需要根据此IP地址进行相关操作\n步骤2. 节点主机名配置 需要在节点1、2、3进行下列操作，将三个主机名分别配置为realtime-1，realtime-2，realtime-3\n通过下列命令使用vi编辑器编辑主机名配置文件： vi /etc/sysconfig/network 打开后的文件内容如下所示：\nNETWORKING=yes HOSTNAME=CentOS6.5 (注：需要将此行内容修改为实际的主机名realtime-1、realtime-2、realtime-3) 在文件中进行内容更改，将HOSTNAME字段内容配置成realtime-： HOSTNAME=realtime-1 编辑完成后保存文件并退出vi编辑器\n更改后的文件内容如下所示：\n更改后的内容会在下次系统重启的时候生效，通过下列命令重新启动系统： reboot 步骤3. 节点1、2、3主机名与IP地址映射文件配置 在节点1、2、3中，通过下列命令使用vi编辑器编辑hosts文件： vi /etc/hosts 打开后的文件内容如下所示：\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 (注：在此行增加内容) ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 增加节点1、2、3的IP地址与主机名的映射关系、节点间的IP地址与主机名的映射关系、节点间的IP地址与主机名的映射关系，IP地址与主机名之间用空格分隔（主机名填写为前文配置的节点实际主机名称，IP地址需要根据上文中的查询结果来进行填写，并与实际的主机名相对应）： 10.1.1.4 realtime-1 10.1.1.3 realtime-2 10.1.1.206 realtime-3 更改后的文件内容如下所示\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.1.1.4 realtime-1 10.1.1.3 realtime-2 10.1.1.206 realtime-3 编辑完成后保存文件并退出vi编辑器\n通过下列命令检测主机名与IP映射是否配置成功： ping realtime-1 -c 2 如果配置成功，则会显示如下结果：\n[root@realtime-1 ~]# ping realtime-1 -c 2 (注：通过此命令向realtime-1节点发送2个报文) PING realtime-1 (10.1.1.4) 56(84) bytes of data. 64 bytes from realtime-1 (10.1.1.4): icmp_seq=1 ttl=64 time=1.98 ms 64 bytes from realtime-1 (10.1.1.4): icmp_seq=2 ttl=64 time=0.341 ms --- realtime-1 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1001ms rtt min/avg/max/mdev = 0.341/1.163/1.985/0.822 ms [root@realtime-1 ~]# 通过下列命令检测主机名与IP映射是否配置成功： ping realtime-2 -c 2 如果配置成功，则会显示如下结果：\n[root@realtime-1 ~]# ping realtime-2 -c 2 (注：通过此命令向realtime-2节点发送2个报文) PING realtime-2 (10.1.1.3) 56(84) bytes of data. 64 bytes from realtime-2 (10.1.1.3): icmp_seq=1 ttl=64 time=0.047 ms 64 bytes from realtime-2 (10.1.1.3): icmp_seq=2 ttl=64 time=0.026 ms --- realtime-2 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.026/0.036/0.047/0.012 ms [root@realtime-1 ~]# 通过下列命令检测主机名与IP映射是否配置成功： ping realtime-3 -c 2 如果配置成功，则会显示如下结果：\n[root@realtime-1 ~]# ping realtime-3 -c 2 (注：通过此命令向realtime-3节点发送2个报文) PING realtime-3 (10.1.1.206) 56(84) bytes of data. 64 bytes from realtime-3 (10.1.1.206): icmp_seq=1 ttl=64 time=1.36 ms 64 bytes from realtime-3 (10.1.1.206): icmp_seq=2 ttl=64 time=0.315 ms --- realtime-3 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1002ms rtt min/avg/max/mdev = 0.315/0.841/1.367/0.526 ms [root@realtime-1 ~]# 如果无法进行正常的报文发送，请检查主机名是否配置正确，同时请检查主机名与IP地址映射是否配置正确。\n2 配置SSH免密码登录 步骤1. 节点1、2、3秘钥配置及分发 例如节点1 : 需要在节点1进行下列操作，在节点1中生成秘钥文件，然后将公钥文件分发到节点2和节点3中，实现在节点1可以免密码登录到集群中的其他主机中。\n通过下面的命令生成密钥（使用rsa加密方式）： echo -e \"\\n\"|ssh-keygen -t rsa -N \"\" \u003e/dev/null 2\u003e\u00261 默认情况下会在~/.ssh/文件夹下生成公钥文件id_rsa.pub和私钥文件id_rsa，通过下面的命令对~/.ssh/内容进行查看：\nll ~/.ssh/ 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ll ~/.ssh/ 总用量 8 -rw-------. 1 root root 1675 11月 29 13:42 id_rsa -rw-r--r--. 1 root root 397 11月 29 13:42 id_rsa.pub [root@realtime-1 ~]# 通过下面的命令将公钥文件发送到本机以及其他两个节点，创建root免密钥通道（需要输入密码：111111）： ssh-copy-id -i /root/.ssh/id_rsa.pub root@realtime-1 # 其他的节点需要随之改动root@realtime-2 and root@realtime-3 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub root@realtime-1 The authenticity of host 'realtime-1 (10.1.1.4)' can't be established. RSA key fingerprint is 9f:3b:30:10:65:46:c9:c3:2b:fb:e5:28:38:39:9c:84. Are you sure you want to continue connecting (yes/no)? yes (注：此处需要输入yes) Warning: Permanently added 'realtime-1,10.1.1.4' (RSA) to the list of known hosts. root@realtime-1's password: （注：此处需要输入root用户密码，为111111） Now try logging into the machine, with \"ssh 'root@realtime-1'\", and check in: .ssh/authorized_keys to make sure we haven't added extra keys that you weren't expecting. [root@realtime-1 ~]# 步骤2. SSH免密码登录测试 集群中各个节点秘钥分发完毕后，可以通过ssh远程登录命令来测试免密码登录是否配置成功。为了操作统一，我们在节点3中进行下面的操作（在其他节点操作所实现的效果也是一样的）\n在节点3中通过下面的命令可以实现免密码远程登录到节点1： ssh realtime-1 #依次运行realtime-2 and realtime-3 命令运行后的返回结果如下所示：\n[root@realtime-3 ~]# ssh realtime-1 Last login: Thu Nov 29 14:08:34 2018 from realtime-3 [root@realtime-1 ~]# 如果从源主机到目的主机的登录过程中，出现需要输入密码的情况，那么需要检查是否已经成功将源主机的公钥文件发送到目的主机中\n3 安装配置JDK1.8 JDK需要在集群3个节点都进行安装，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行\n我们可以在Oracle JDK的官网下载相应版本的JDK，官网地址为: http://www.oracle.com/technetwork/java/javase/downloads/index.html\n步骤1. 创建工作路径 首先需要在终端中输入下列命令，在/usr目录下建立cx工作路径： mkdir /usr/cx 通过下面的命令实现在节点2和节点3的/usr目录下建立cx工作路径： ssh realtime-2 \"mkdir /usr/cx\" ssh realtime-3 \"mkdir /usr/cx\" 步骤2. 解压安装包 我们可以在/usr/software/目录下找到jdk-8u60-linux-x64.tar.gz安装包，通过下列命令将其解压到/usr/cx/目录下： tar -zxvf /usr/software/jdk-8u60-linux-x64.tar.gz -C /usr/cx 命令执行后的输出内容如下所示：\n(-------------------省略------------------------) jdk1.8.0_60/bin/jmc.ini jdk1.8.0_60/bin/jmap jdk1.8.0_60/bin/serialver jdk1.8.0_60/bin/wsgen jdk1.8.0_60/bin/jrunscript jdk1.8.0_60/bin/javah jdk1.8.0_60/bin/javac jdk1.8.0_60/bin/jvisualvm jdk1.8.0_60/bin/jcontrol jdk1.8.0_60/release [root@realtime-1 ~]# 通过下列命令实现在节点2和节点3中将jdk-8u60-linux-x64.tar.gz安装包解压到/usr/cx/目录下： ssh realtime-2 \"tar -zxvf /usr/software/jdk-8u60-linux-x64.tar.gz -C /usr/cx\" ssh realtime-3 \"tar -zxvf /usr/software/jdk-8u60-linux-x64.tar.gz -C /usr/cx\" 步骤3. 配置环境变量 通过下列命令使用vi编辑器打开 ~/.bashrc文件： vi ~/.bashrc 打开的~/.bashrc文件内容如下所示：\n# .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi (----------------注：需要在此处增加内容-------------------) 在文件中写入下列内容： export JAVA_HOME=/usr/cx/jdk1.8.0_60 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/tools.jar 编辑完成后保存文件并退出vi编辑器。\n通过下面的命令将环境变量配置文件分发到节点2和节点3： scp ~/.bashrc root@realtime-2:~/.bashrc scp ~/.bashrc root@realtime-3:~/.bashrc 命令执行后的输出内容如下所示：\n[root@realtime-1 ~]# scp ~/.bashrc root@realtime-2:~/.bashrc .bashrc 100% 320 0.3KB/s 00:00 [root@realtime-1 ~]# 步骤4. 更新环境变量 执行如下命令，更新环境变量： source ~/.bashrc 执行如下命令，更新节点2和节点3的环境变量： ssh realtime-2 \"source ~/.bashrc\" ssh realtime-3 \"source ~/.bashrc\" 步骤5. 验证JDK是否配置成功 通过下面的命令验证JDK是否安装并配置成功： java -version 如果出现如下JDK版本信息，则说明安装配置成功：\n[root@realtime-1 ~]# java -version java version \"1.8.0_60\" (注：JDK版本号) Java(TM) SE Runtime Environment (build 1.8.0_60-b27) (注：Java运行环境版本号) Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode) [root@realtime-1 ~]# 通过下面的命令验证节点2和节点3的JDK是否安装并配置成功： ssh realtime-2 \"java -version\" ssh realtime-3 \"java -version\" 如果没有正确输出相关版本信息，请检查~/.bashrc文件中的JDK环境变量是否配置正确，同时请确定是否使用source ~/.bashrc命令更新环境变量配置\n4 NTP服务配置 需要在集群的3台节点中都进行NTP服务的配置\n步骤1. NTP服务配置 在节点1、节点2、节点3中通过下面的命令打开NTP配置文件： vi /etc/ntp.conf 打开后的文件内容如下所示：\n（---------------省略----------------） # Permit all access over the loopback interface. This could # be tightened as well, but to do so would effect some of # the administrative functions. restrict 127.0.0.1 restrict -6 ::1 # Hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst （注：注释此行内容） server 1.centos.pool.ntp.org iburst （注：注释此行内容） server 2.centos.pool.ntp.org iburst （注：注释此行内容） server 3.centos.pool.ntp.org iburst （注：注释此行内容） （注：在此处增加内容） #broadcast 192.168.1.255 autokey # broadcast server （---------------省略----------------） 在文件中进行下列内容更改（通过server字段设置本机为NTP Serevr服务器，通过restrict限制realtime-2和realtime-3主机名对应的主机可以同步时间）：\n#server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server 127.127.1.0 fudge 127.127.1.0 stratum 10 restrict realtime-2 nomodify notrap restrict realtime-3 nomodify notrap 更改完成后保存文件并退出编辑器\n步骤2. 启动NTP服务 为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行。\n通过下面的命令在节点1中设定NTP服务自启动： chkconfig ntpd on 通过下面的命令在节点1中启动NTP服务： service ntpd start 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# service ntpd start 正在启动 ntpd： [确定] [root@realtime-1 ~]# 通过下面的命令在节点2中设定NTP服务自启动： ssh realtime-2 \"chkconfig ntpd on\" 通过下面的命令在节点2中启动NTP服务： ssh realtime-2 \"service ntpd start\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh realtime-2 \"service ntpd start\" 正在启动 ntpd：[确定] [root@realtime-1 ~]# 通过下面的命令在节点3中设定NTP服务自启动： ssh realtime-3 \"chkconfig ntpd on\" 通过下面的命令在节点3中启动NTP服务： ssh realtime-3 \"service ntpd start\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh realtime-3 \"service ntpd start\" 正在启动 ntpd：[确定] [root@realtime-1 ~]# 如果服务无法正常启动，会出现相关的错误提示信息，只需要根据错误提示进行更改即可。\n步骤3. NTP服务状态查看 为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行。\n通过下面的命令查看节点1中NTP服务的运行状态： ntpstat 命令运行后的返回结果如下所示（由于节点1是作为Server节点，所以其状态会很快变成synchronised，此时说明服务已经正常启动）：\n[root@realtime-1 ~]# ntpstat synchronised to local net at stratum 11 time correct to within 449 ms polling server every 64 s [root@realtime-1 ~]# 通过下面的命令查看节点2和节点三中NTP服务的运行状态： ssh realtime-2 \"ntpstat\" ssh realtime-3 \"ntpstat\" 命令运行后的返回结果如下所示（由于节点2需要同步节点1的时间，因此需要大概15分钟其状态才会由unsynchronised会变成synchronised，当状态变为synchronised时说明服务已经正常启动）：\n[root@realtime-1 ~]# ssh realtime-2 \"ntpstat\" unsynchronised polling server every 64 s [root@realtime-1 ~]# 服务正常启动后的状态如下所示：\n[root@realtime-1 ~]# ssh realtime-3 \"ntpstat\" synchronised to NTP server (10.1.1.4) at stratum 12 time correct to within 25 ms polling server every 64 s [root@realtime-1 ~]# 当3个节点的状态都显示为synchronised时，则表示ntp服务已经启动成功；如果一直显示unsynchronised,可能是配置文件有错误，因此需要检查IP地址是否配置正确。\n同学们不必一直等待，可以先进行下文的实验，然后过后再查看NTP服务状态。\n5 SElinux安全配置 需要在集群3个节点都进行SElinux配置，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行。\n通过下面的命令，关闭节点1、节点2、节点3的SElinux安全设置： /bin/sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config ssh realtime-2 \"/bin/sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config\" ssh realtime-3 \"/bin/sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config\" 6 安装配置ZooKeeper集群 由于我们需要搭建一套具备高可用性的Hadoop集群，因此需要通过ZooKeeper来进行集群中服务的协调。ZooKeeper需要在集群3个节点进行安装配置，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行\n在模板中我们已经将ZooKeeper安装文件zookeeper-3.4.6.tar.gz放到了/usr/software目录下，同学们可以直接使用\n步骤1. 解压安装包 通过下列命令将ZooKeeper安装包解压到/usr/cx目录下： tar -zxvf /usr/software/zookeeper-3.4.6.tar.gz -C /usr/cx 命令运行后的返回结果如下所示：\n(---------------------省略--------------------) zookeeper-3.4.6/recipes/queue/test/org/apache/zookeeper/recipes/queue/DistributedQueueTest.java zookeeper-3.4.6/recipes/queue/build.xml zookeeper-3.4.6/zookeeper-3.4.6.jar zookeeper-3.4.6/lib/ zookeeper-3.4.6/lib/cobertura/ zookeeper-3.4.6/lib/cobertura/README.txt zookeeper-3.4.6/lib/jline-0.9.94.jar zookeeper-3.4.6/lib/log4j-1.2.16.LICENSE.txt zookeeper-3.4.6/lib/slf4j-log4j12-1.6.1.jar zookeeper-3.4.6/lib/jdiff/ zookeeper-3.4.6/lib/jdiff/zookeeper_3.1.1.xml zookeeper-3.4.6/lib/jdiff/zookeeper_3.4.6-SNAPSHOT.xml zookeeper-3.4.6/lib/jdiff/zookeeper_3.4.6.xml zookeeper-3.4.6/lib/slf4j-api-1.6.1.jar zookeeper-3.4.6/lib/log4j-1.2.16.jar zookeeper-3.4.6/lib/netty-3.7.0.Final.jar zookeeper-3.4.6/lib/jline-0.9.94.LICENSE.txt [root@realtime-1 ~]# 解压完成后，我们可以查看解压后的文件夹内容： ls /usr/cx/zookeeper-3.4.6/ 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ls /usr/cx/zookeeper-3.4.6/ bin dist-maven LICENSE.txt src build.xml docs NOTICE.txt zookeeper-3.4.6.jar CHANGES.txt ivysettings.xml README_packaging.txt zookeeper-3.4.6.jar.asc conf ivy.xml README.txt zookeeper-3.4.6.jar.md5 contrib lib recipes zookeeper-3.4.6.jar.sha1 [root@realtime-1 ~]# 步骤2. 数据存储目录创建 通过下面的命令创建ZooKeeper数据存储目录： mkdir -p /home/data 通过下面的命令创建ZooKeeper日志存储目录：\nmkdir -p /home/logs 通过下面的命令在节点2、节点3中创建ZooKeeper数据存储目录： ssh realtime-2 \"mkdir -p /home/data\" ssh realtime-3 \"mkdir -p /home/data\" 通过下面的命令在节点2、节点3中创建ZooKeeper日志存储目录：\nssh realtime-2 \"mkdir -p /home/logs\" ssh realtime-3 \"mkdir -p /home/logs\" 步骤3. 主机myid编号文件创建 通过下面的命令创建myid文件，并设置节点1对应的编号为1（集群启动后会通过此编号来进行主机识别）： echo \"1\" \u003e /home/data/myid 通过下面的命令在节点2中创建myid文件，并设置节点2对应的编号为2（集群启动后会通过此编号来进行主机识别）： ssh realtime-2 \"echo \"2\" \u003e /home/data/myid\" 通过下面的命令在节点3中创建myid文件，并设置节点3对应的编号为3（集群启动后会通过此编号来进行主机识别）： ssh realtime-3 \"echo \"3\" \u003e /home/data/myid\" 步骤4. ZooKeeper配置文件编辑 通过下列命令创建并打开zoo.cfg配置文件： vi /usr/cx/zookeeper-3.4.6/conf/zoo.cfg 在文件中写入下列内容：\ntickTime=2000 dataDir=/home/data clientPort=2181 dataLogDir=/home/logs initLimit=5 syncLimit=2 server.1=realtime-1:2888:3888 server.2=realtime-2:2888:3888 server.3=realtime-3:2888:3888 编辑完成后保存文件并退出vi编辑器。\n在上述配置中，我们设置心跳时间为2000毫秒，设置ZooKeeper在本地保存数据的目录为/home/data，ZooKeeper监听客户端连接的端口为2181,设置所有Follower和Leader进行同步的时间为5s，设置一个Follower和Leader进行同步的时间为2s。同时设定集群中有3台主机，其中realtime-1对应的主机编号为1，Follower与Leader之间交换信息的端口为2888，进行Leader选举的端口为3888；realtime-2对应的主机编号为2，Follower与Leader之间交换信息的端口为2888，进行Leader选举的端口为3888；realtime-3对应的主机编号为3，Follower与Leader之间交换信息的端口为2888，进行Leader选举的端口为3888。\n步骤5. 文件分发 通过下面的命令将节点1的ZooKeeper文件包分发到节点2、节点3中： scp -r /usr/cx/zookeeper-3.4.6 root@realtime-2:/usr/cx/ scp -r /usr/cx/zookeeper-3.4.6 root@realtime-3:/usr/cx/ 命令运行后的返回结果如下所示：\n（----------------------省略------------------------） Makefile.am 100% 74 0.1KB/s 00:00 zkServer.cmd 100% 1084 1.1KB/s 00:00 zkEnv.sh 100% 2696 2.6KB/s 00:00 zkCleanup.sh 100% 1937 1.9KB/s 00:00 zkCli.sh 100% 1534 1.5KB/s 00:00 zkEnv.cmd 100% 1333 1.3KB/s 00:00 zkCli.cmd 100% 1049 1.0KB/s 00:00 README.txt 100% 238 0.2KB/s 00:00 zkServer.sh 100% 5742 5.6KB/s 00:00 NOTICE.txt 100% 170 0.2KB/s 00:00 zookeeper-3.4.6.jar.md5 100% 33 0.0KB/s 00:00 README.txt 100% 1585 1.6KB/s 00:00 CHANGES.txt 100% 79KB 78.9KB/s 00:00 zookeeper-3.4.6.jar.sha1 100% 41 0.0KB/s 00:00 [root@realtime-1 ~]# 步骤6. ZooKeeper环境变量配置 通过下列命令使用vi编辑器打开 ~/.bashrc文件： vi ~/.bashrc 打开的~/.bashrc文件内容如下所示：\n# .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi export JAVA_HOME=/usr/cx/jdk1.8.0_60 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/tools.jar (----------------注：需要在此处增加内容-------------------) 在文件中写入下列内容： export ZK_HOME=/usr/cx/zookeeper-3.4.6 export PATH=$PATH:$ZK_HOME/bin 编辑完成后保存文件并退出vi编辑器。\n通过下面的命令将环境变量配置文件分发到节点2和节点3： scp ~/.bashrc root@realtime-2:~/.bashrc scp ~/.bashrc root@realtime-3:~/.bashrc 步骤7. 更新环境变量 执行如下命令，更新环境变量： source ~/.bashrc ssh realtime-2 \"source ~/.bashrc\" ssh realtime-3 \"source ~/.bashrc\" 步骤8. 验证环境变量是否配置成功 通过下面的命令验证环境变量是否配置成功： zkServer.sh ssh realtime-2 \"zkServer.sh\" ssh realtime-3 \"zkServer.sh\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# zkServer.sh JMX enabled by default Using config: /usr/cx/zookeeper-3.4.6/bin/../conf/zoo.cfg Usage: /usr/cx/zookeeper-3.4.6/bin/zkServer.sh {start|start-foreground|stop|restart|status|upgrade|print-cmd} [root@realtime-1 ~]# 由输出内容可以看出，ZooKeeper环境变量已经配置正确，并且可以正常执行。\n7 ZooKeeper启动及状态查看 步骤1. ZooKeeper启动 通过下面的命令启动ZooKeeper服务： zkServer.sh start ssh realtime-2 \"zkServer.sh start\" ssh realtime-3 \"zkServer.sh start\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# zkServer.sh start JMX enabled by default Using config: /usr/cx/zookeeper-3.4.6/bin/../conf/zoo.cfg Starting zookeeper ... STARTED [root@realtime-1 ~]# 步骤2. ZooKeeper运行状态查看 ZooKeeper运行之后会随机进行follower角色以及leader角色选举，当leader角色节点出现异常后，会从其他节点中选举出新的leader角色。至于具体哪个节点处于leader状态，需要根据实际情况确定，并不是千篇一律的\n通过下面的命令可以查看ZooKeeper运行状态：\nzkServer.sh status ssh realtime-2 \"zkServer.sh status\" ssh realtime-3 \"zkServer.sh status\" 命令运行后的返回结果如下所示（由返回结果的Mode字段可以看出，当前节点是作为follower角色运行的）：\n[root@realtime-1 ~]# zkServer.sh status JMX enabled by default Using config: /usr/cx/zookeeper-3.4.6/bin/../conf/zoo.cfg Mode: follower [root@realtime-1 ~]# 8 安装配置Hadoop集群 Hadoop需要在集群3个节点进行安装配置，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行\n在模板中，我们已经将相应的Hadoop安装包hadoop-2.7.1.tar.gz放到/usr/software/目录下，同学们不需要再次下载，可以直接使用。\n步骤1. 数据存储目录创建 mkdir -p /hdfs/namenode mkdir -p /hdfs/datanode mkdir -p /hdfs/journalnode mkdir -p /var/log/hadoop-yarn ssh realtime-2 \"mkdir -p /hdfs/namenode\" ssh realtime-2 \"mkdir -p /hdfs/datanode\" ssh realtime-2 \"mkdir -p /hdfs/journalnode\" ssh realtime-2 \"mkdir -p /var/log/hadoop-yarn\" ssh realtime-3 \"mkdir -p /hdfs/namenode\" ssh realtime-3 \"mkdir -p /hdfs/datanode\" ssh realtime-3 \"mkdir -p /hdfs/journalnode\" ssh realtime-3 \"mkdir -p /var/log/hadoop-yarn\" 步骤2. 解压安装文件 通过下列命令解压Hadoop安装文件，将文件解压到/usr/cx目录下：\ntar -zxvf /usr/software/hadoop-2.7.1.tar.gz -C /usr/cx 命令执行后的输出内容如下所示：\n(-------------------省略------------------------) hadoop-2.7.1/libexec/hdfs-config.sh hadoop-2.7.1/README.txt hadoop-2.7.1/NOTICE.txt hadoop-2.7.1/lib/ hadoop-2.7.1/lib/native/ hadoop-2.7.1/lib/native/libhadoop.a hadoop-2.7.1/lib/native/libhadoop.so hadoop-2.7.1/lib/native/libhadooppipes.a hadoop-2.7.1/lib/native/libhdfs.so.0.0.0 hadoop-2.7.1/lib/native/libhadooputils.a hadoop-2.7.1/lib/native/libhdfs.a hadoop-2.7.1/lib/native/libhdfs.so hadoop-2.7.1/lib/native/libhadoop.so.1.0.0 hadoop-2.7.1/LICENSE.txt [root@master ~]# 步骤3. 编辑Hadoop配置文件： 使用vi命令打开hadoop-env.sh配置文件进行编辑： vi /usr/cx/hadoop-2.7.1/etc/hadoop/hadoop-env.sh 打开后的文件内容如下所示：\n(-------------------省略------------------------) # Set Hadoop-specific environment variables here. # The only required environment variable is JAVA_HOME. All others are # optional. When running a distributed configuration it is best to # set JAVA_HOME in this file, so that it is correctly defined on # remote nodes. # The java implementation to use. export JAVA_HOME=${JAVA_HOME} (注：需要对此行内容进行更改，为Hadoop绑定Java运行环境) # The jsvc implementation to use. Jsvc is required to run secure datanodes # that bind to privileged ports to provide authentication of data transfer # protocol. Jsvc is not required if SASL is configured for authentication of # data transfer protocol using non-privileged ports. #export JSVC_HOME=${JSVC_HOME} export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-\"/etc/hadoop\"} (-------------------省略------------------------) 在文件中进行下列内容更改，将JAVA_HOME对应的值改成实际的JDK安装路径：\nexport JAVA_HOME=/usr/cx/jdk1.8.0_60\n编辑完成后保存文件并退出vi编辑器。\n使用vi命令打开hdfs-site.xml文件进行配置： vi /usr/cx/hadoop-2.7.1/etc/hadoop/hdfs-site.xml 打开后的文件内容如下所示：\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e (注：需要在此处进行相关内容配置) 在文件中和之间增加下列内容：\n/*配置DataNode的数据存储目录，需要与上文创建的目录相对应*/ dfs.datanode.data.dir /hdfs/datanode /*配置数据块大小为256M*/ dfs.blocksize 268435456 /*自定义的HDFS服务名，在高可用集群中，无法配置单一HDFS服务器入口，所以需要指定一个逻辑上的服务名，当访问服务名时，会自动选择NameNode节点进行访问*/ dfs.nameservices HDFScluster /*配置NameNode的数据存储目录，需要与上文创建的目录相对应*/ dfs.namenode.name.dir /hdfs/namenode /*定义HDFS服务名所指向的NameNode主机名称*/ dfs.ha.namenodes.HDFScluster realtime-1,realtime-2 /*设置NameNode的完整监听地址*/ dfs.namenode.rpc-address.HDFScluster.realtime-1 realtime-1:8020 /*设置NameNode的完整监听地址*/ dfs.namenode.rpc-address.HDFScluster.realtime-2 realtime-2:8020 /*设置NameNode的HTTP访问地址*/ dfs.namenode.http-address.HDFScluster.realtime-1 realtime-1:50070 /*设置NameNode的HTTP访问地址*/ dfs.namenode.http-address.HDFScluster.realtime-2 realtime-2:50070 /*设置主从NameNode元数据同步地址，官方推荐将nameservice作为最后的journal ID*/ dfs.namenode.shared.edits.dir qjournal://realtime-1:8485;realtime-2:8485;realtime-3:8485/HDFScluster /*设置HDFS客户端用来连接集群中活动状态NameNode节点的Java类*/ dfs.client.failover.proxy.provider.HDFScluster org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider /*设置SSH登录的私钥文件地址*/ dfs.ha.fencing.ssh.private-key-files /root/.ssh/id_rsa /*启动fence过程，确保集群高可用性*/ dfs.ha.fencing.methods shell(/bin/true) /*配置JournalNode的数据存储目录，需要与上文创建的目录相对应*/ dfs.journalnode.edits.dir /hdfs/journalnode /*设置自动切换活跃节点，保证集群高可用性*/ dfs.ha.automatic-failover.enabled true /*配置数据块副本数*/ dfs.replication 3 /*将dfs.webhdfs.enabled属性设置为true，否则就不能使用webhdfs的LISTSTATUS、LIST FILESTATUS等需要列出文件、文件夹状态的命令，因为这些信息都是由namenode保存的*/ dfs.webhdfs.enabled true 编辑完成后保存文件并退出vi编辑器\n在集群中，对HDFS集群访问的入口是NameNode所在的服务器。但是在两个NameNode节点的HA集群中，无法配置单一服务器入口，所以需要通过dfs.nameservices指定一个逻辑上的服务名，这个服务名是自定义的。当外界访问HDFS集群时，入口就变为这个服务名称，Hadoop会自动实现将访问请求转发到实际的处于Active状态的NameNode节点上。\n当配置了HDFS HA集群时，会有两个NameNode，为了避免两个NameNode都为Active状态，当发生failover时，Standby的节点要执行一系列方法把原来那个Active节点中不健康的NameNode服务给杀掉（这个过程就称为fence）。而dfs.ha.fencing.methods配置就是配置了执行杀死原来Active NameNode服务的方法，为了保险起见，因此指定无论如何都把StandBy节点的状态提升为Active，所以最后要配置一个shell(/bin/true)，保证不论前面的方法执行的情况如何，最后fence过程返回的结果都为True。fence操作需要通过SSH进行节点间的访问，因此需要配置dfs.ha.fencing.ssh.private-key-files为所需要用到的私钥文件路径信息。\n使用vi命令打开core-site.xml配置文件进行编辑： vi /usr/cx/hadoop-2.7.1/etc/hadoop/core-site.xml 打开后的文件内容如下所示：\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e (注：需要在此处进行相关内容配置) 在文件中和之间增加下列内容：\n/*设置默认的HDFS访问路径，需要与hdfs-site.xml中的HDFS服务名相一致*/ fs.defaultFS hdfs://HDFScluster /*临时文件夹路径设置*/ hadoop.tmp.dir /usr/tmp /*配置ZooKeeper服务集群，用于活跃NameNode节点的选举*/ ha.zookeeper.quorum realtime-1:2181,realtime-2:2181,realtime-3:2181 /*设置数据压缩算法*/ io.compression.codecs org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.SnappyCodec io.compression.codec.lzo.class com.hadoop.compression.lzo.LzoCodec /*设置使用hduser用户可以代理所有主机用户进行任务提交*/ hadoop.proxyuser.hduser.host * /*设置使用hduser用户可以代理所有组用户进行任务提交*/ hadoop.proxyuser.hduser.groups * 编辑完成后保存文件并退出vi编辑器\n对HDFS集群访问的入口是NameNode所在的服务器，但是在两个NameNode节点的HA集群中，无法配置单一服务器入口，所以需要在hdfs-site.xml中通过dfs.nameservices指定一个逻辑上的服务名，因此此处的fs.defaultFS配置的入口地址需要与hdfs-site.xml中dfs.nameservices所配置的一致。\n使用vi命令打开yarn-site.xml文件进行配置： vi /usr/cx/hadoop-2.7.1/etc/hadoop/yarn-site.xml 打开后的文件内容如下所示：\n\u003c?xml version=\"1.0\"?\u003e (注：需要在此处进行相关内容配置) 在文件中和之间增加下列内容：\n/*设置NodeManager上运行的附属服务，需配置成mapreduce_shuffle才可运行MapReduce程序*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services.mapreduce_shuffle.class\u003c/name\u003e \u003cvalue\u003eorg.apache.hadoop.mapred.ShuffleHandler\u003c/value\u003e \u003c/property\u003e /*设置任务日志存储目录*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.log-dirs\u003c/name\u003e \u003cvalue\u003efile:///var/log/hadoop-yarn \u003c/value\u003e \u003c/property\u003e /*设置Hadoop依赖包地址*/ \u003cproperty\u003e \u003cname\u003eyarn.application.classpath\u003c/name\u003e \u003cvalue\u003e $HADOOP_HOME/share/hadoop/common/*,$HADOOP_HOME/share/hadoop/common/lib/*, $HADOOP_HOME/share/hadoop/hdfs/*,$HADOOP_HOME/share/hadoop/hdfs/lib/*, $HADOOP_HOME/share/hadoop/mapreduce/*,$HADOOP_HOME/share/hadoop/mapreduce/lib/*, $HADOOP_HOME/share/hadoop/yarn/*,$HADOOP_HOME/share/hadoop/yarn/lib/* \u003c/value\u003e \u003c/property\u003e /*开启resourcemanager 的高可用性功能*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.ha.enabled\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e /*标识集群中的resourcemanager，如果设置该选项，需要确保所有的resourcemanager节点在配置中都有自己的逻辑id*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.cluster-id\u003c/name\u003e \u003cvalue\u003eYARNcluster\u003c/value\u003e \u003c/property\u003e /*设置resourcemanager节点的逻辑id*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.ha.rm-ids\u003c/name\u003e \u003cvalue\u003erm1,rm2\u003c/value\u003e \u003c/property\u003e /*为每个逻辑id绑定实际的主机名称*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname.rm1\u003c/name\u003e \u003cvalue\u003erealtime-1\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname.rm2\u003c/name\u003e \u003cvalue\u003erealtime-2\u003c/value\u003e \u003c/property\u003e /*指定ZooKeeper服务地址*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.zk-address\u003c/name\u003e \u003cvalue\u003erealtime-1:2181,realtime-2:2181,realtime-3:2181\u003c/value\u003e \u003c/property\u003e /*指定resourcemanager的WEB访问地址*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.webapp.address.rm1\u003c/name\u003e \u003cvalue\u003erealtime-1:8089\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.webapp.address.rm2\u003c/name\u003e \u003cvalue\u003erealtime-2:8089\u003c/value\u003e \u003c/property\u003e /*设定虚拟内存与实际内存的比例，比例值越高，则可用虚拟内存就越多*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.vmem-pmem-ratio\u003c/name\u003e \u003cvalue\u003e3\u003c/value\u003e \u003c/property\u003e /*设定单个容器可以申领到的最小内存资源*/ \u003cproperty\u003e \u003cname\u003eyarn.scheduler.minimum-allocation-mb\u003c/name\u003e \u003cvalue\u003e32\u003c/value\u003e \u003c/property\u003e /*设置当任务运行结束后，日志文件被转移到的HDFS目录*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.remote-app-log-dir\u003c/name\u003e \u003cvalue\u003ehdfs://HDFScluster/var/log/hadoop-yarn/apps\u003c/value\u003e \u003c/property\u003e /*设定资源调度策略，目前可用的有FIFO、Capacity Scheduler和Fair Scheduler*/ \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.scheduler.class\u003c/name\u003e \u003cvalue\u003eorg.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\u003c/value\u003e \u003c/property\u003e /*设定每个任务能够申领到的最大虚拟CPU数目*/ \u003cproperty\u003e \u003cname\u003eyarn.scheduler.maximum-allocation-vcores\u003c/name\u003e \u003cvalue\u003e8\u003c/value\u003e \u003c/property\u003e /*设置任务完成指定时间（秒）之后，删除任务的本地化文件和日志目录*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.delete.debug-delay-sec\u003c/name\u003e \u003cvalue\u003e600\u003c/value\u003e \u003c/property\u003e /*设置志在HDFS上保存多长时间（秒）*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.log.retain-seconds\u003c/name\u003e \u003cvalue\u003e86400\u003c/value\u003e \u003c/property\u003e /*设定物理节点有2G内存加入资源池*/ \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.resource.memory-mb\u003c/name\u003e \u003cvalue\u003e2048\u003c/value\u003e \u003c/property\u003e 编辑完成后保存文件并退出vi编辑器\n在集群中，提交任务的入口是ResourceManager所在的服务器。但是在两个ResourceManager节点的HA集群中，无法配置单一服务器入口，所以需要通过yarn.resourcemanager.cluster-id指定一个逻辑上的服务名，这个服务名是自定义的。当外界向集群提交任务时，入口就变为这个服务名称，YARN会自动实现将访问请求转发到实际的处于Active状态的ResourceManager节点上。由于配置了逻辑服务名，所以需要设置resourcemanager节点的逻辑id，并为每个逻辑id绑定实际的主机名称\n使用下列命令复制mapred-site.xml.template文件并重命名为mapred-site.xml： cp /usr/cx/hadoop-2.7.1/etc/hadoop/mapred-site.xml.template /usr/cx/hadoop-2.7.1/etc/hadoop/mapred-site.xml 使用vi命令打开mapred-site.xml文件进行配置： vi /usr/cx/hadoop-2.7.1/etc/hadoop/mapred-site.xml 打开后的文件内容如下所示：\n\u003c?xml version=\"1.0\"?\u003e \u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e (注：需要在此处进行相关内容配置) 在文件中和之间增加下列内容：\n/*Hadoop对MapReduce运行框架一共提供了3种实现，在mapred-site.xml中通过\"mapreduce.framework.name\"这个属性来设置为\"classic\"、\"yarn\"或者\"local\"*/ mapreduce.framework.name yarn 编辑完成后保存文件并退出vi编辑器\n使用vi命令打开slaves文件进行配置（要与我们前文设置的主机名相互一致，否则将会引起Hadoop相关进程无法正确启动）： vi /usr/cx/hadoop-2.7.1/etc/hadoop/slaves 打开后的文件内容如下所示：\nlocalhost （注：需要对此内容进行更改，配置为Slave节点的实际主机名） 将文件中的内容更改为下列内容：\nrealtime-1 realtime-2 realtime-3 编辑完成后保存文件并退出vi编辑器\n步骤4. 文件分发 通过下面的命令将节点1的Hadoop文件包分发到节点2中： scp -r /usr/cx/hadoop-2.7.1 root@realtime-2:/usr/cx/ 命令运行后的返回结果如下所示：\n（---------------------省略-----------------------） external.png 100% 230 0.2KB/s 00:00 banner.jpg 100% 872 0.9KB/s 00:00 maven-feather.png 100% 3330 3.3KB/s 00:00 build-by-maven-white.png 100% 2260 2.2KB/s 00:00 build-by-maven-black.png 100% 2294 2.2KB/s 00:00 bg.jpg 100% 486 0.5KB/s 00:00 icon_error_sml.gif 100% 1010 1.0KB/s 00:00 logo_apache.jpg 100% 33KB 32.7KB/s 00:00 collapsed.gif 100% 820 0.8KB/s 00:00 apache-maven-project-2.png 100% 33KB 32.7KB/s 00:00 icon_success_sml.gif 100% 990 1.0KB/s 00:00 icon_info_sml.gif 100% 606 0.6KB/s 00:00 h3.jpg 100% 431 0.4KB/s 00:00 maven-logo-2.gif 100% 26KB 25.8KB/s 00:00 h5.jpg 100% 357 0.4KB/s 00:00 newwindow.png 100% 220 0.2KB/s 00:00 icon_warning_sml.gif 100% 576 0.6KB/s 00:00 expanded.gif 100% 52 0.1KB/s 00:00 dependency-analysis.html 100% 21KB 21.3KB/s 00:00 [root@realtime-1 ~]# 通过下面的命令将节点1的Hadoop文件包分发到节点3中： scp -r /usr/cx/hadoop-2.7.1 root@realtime-3:/usr/cx/ 命令运行后的返回结果如下所示：\n（---------------------省略-----------------------） external.png 100% 230 0.2KB/s 00:00 banner.jpg 100% 872 0.9KB/s 00:00 maven-feather.png 100% 3330 3.3KB/s 00:00 build-by-maven-white.png 100% 2260 2.2KB/s 00:00 build-by-maven-black.png 100% 2294 2.2KB/s 00:00 bg.jpg 100% 486 0.5KB/s 00:00 icon_error_sml.gif 100% 1010 1.0KB/s 00:00 logo_apache.jpg 100% 33KB 32.7KB/s 00:00 collapsed.gif 100% 820 0.8KB/s 00:00 apache-maven-project-2.png 100% 33KB 32.7KB/s 00:00 icon_success_sml.gif 100% 990 1.0KB/s 00:00 icon_info_sml.gif 100% 606 0.6KB/s 00:00 h3.jpg 100% 431 0.4KB/s 00:00 maven-logo-2.gif 100% 26KB 25.8KB/s 00:00 h5.jpg 100% 357 0.4KB/s 00:00 newwindow.png 100% 220 0.2KB/s 00:00 icon_warning_sml.gif 100% 576 0.6KB/s 00:00 expanded.gif 100% 52 0.1KB/s 00:00 dependency-analysis.html 100% 21KB 21.3KB/s 00:00 [root@realtime-1 ~]# 步骤5. 配置Hadoop环境变量 通过下列命令使用vi编辑器编辑~/.bashrc文件： vi ~/.bashrc 打开后的文件内容如下所示：\n# .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi export JAVA_HOME=/usr/cx/jdk1.8.0_60 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/tools.jar export ZK_HOME=/usr/cx/zookeeper-3.4.6 export PATH=$PATH:$ZK_HOME/bin (----------------在此处增加内容-------------------) 在~/.bashrc文件中增加以下内容： export HADOOP_HOME=/usr/cx/hadoop-2.7.1 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin 编辑完成后保存文件并退出vi编辑器\n通过下面的命令将节点1的环境变量文件分发到节点2中： scp -r ~/.bashrc root@realtime-2:~/.bashrc 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# scp -r ~/.bashrc root@realtime-2:~/.bashrc .bashrc 100% 502 0.5KB/s 00:00 [root@realtime-1 ~]# 通过下面的命令将节点1的环境变量文件分发到节点3中： scp -r ~/.bashrc root@realtime-3:~/.bashrc 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# scp -r ~/.bashrc root@realtime-3:~/.bashrc .bashrc 100% 502 0.5KB/s 00:00 [root@realtime-1 ~]# 步骤6. 更新环境变量 执行如下命令，更新环境变量： source ~/.bashrc ssh realtime-2 \"source ~/.bashrc\" ssh realtime-3 \"source ~/.bashrc\" 步骤7. 验证Hadoop环境变量是否配置成功 通过下列命令验证Hadoop环境变量是否配置成功： hadoop ssh realtime-2 \"hadoop\" ssh realtime-3 \"hadoop\" 如果出现如下提示信息，则说明Hadoop安装配置成功： [root@realtime-1 ~]# hadoop Usage: hadoop [--config confdir] [COMMAND | CLASSNAME] CLASSNAME run the class named CLASSNAME or where COMMAND is one of: fs run a generic filesystem user client version print the version jar run a jar file note: please use \"yarn jar\" to launch YARN applications, not this command. checknative [-a|-h] check native hadoop and compression libraries availability distcp copy file or directories recursively archive -archiveName NAME -p * create a hadoop archive classpath prints the class path needed to get the credential interact with credential providers Hadoop jar and the required libraries daemonlog get/set the log level for each daemon trace view and modify Hadoop tracing settings Most commands print help when invoked w/o parameters. [root@realtime-1 ~]# 如果没有正确输出相关信息，请检查~/.bashrc文件中的Hadoop环境变量是否配置正确，同时请确定是否使用source ~/.bashrc命令更新环境变量配置\n步骤8. 格式化HDFS 通过下列命令格式化HDFS文件系统（如果格式化失败，会有相关的错误日志输出，根据输出内容进行更改即可）：\nhadoop namenode -format 命令运行后的部分显示内容如下所示：\n(-------------------省略------------------------) 18/11/30 11:07:15 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25 18/11/30 11:07:15 INFO namenode.FSNamesystem: Retry cache on namenode is enabled 18/11/30 11:07:15 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis 18/11/30 11:07:15 INFO util.GSet: Computing capacity for map NameNodeRetryCache 18/11/30 11:07:15 INFO util.GSet: VM type = 64-bit 18/11/30 11:07:15 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB 18/11/30 11:07:15 INFO util.GSet: capacity = 2^15 = 32768 entries 18/11/30 11:07:16 INFO namenode.FSImage: Allocated new BlockPoolId: BP-348760827-10.1.1.4-1543547236332 18/11/30 11:07:16 INFO common.Storage: Storage directory /hdfs/namenode has been successfully formatted. 18/11/30 11:07:16 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid \u003e= 0 18/11/30 11:07:16 INFO util.ExitUtil: Exiting with status 0 18/11/30 11:07:16 INFO namenode.NameNode: SHUTDOWN_MSG: /************************************************************ SHUTDOWN_MSG: Shutting down NameNode at realtime-1/10.1.1.4 ************************************************************/ [root@realtime-1 ~]# 步骤9. 格式化zkfc元数据 通过下面的命令格式化DFSZKFailoverController(ZKFC)元数据（在一个节点中进行处理即可）：\nhdfs zkfc -formatZK 命令运行后的返回结果如下所示：\n（---------------省略------------------） tString=realtime-1:2181,realtime-2:2181,realtime-3:2181 sessionTimeout=5000 watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@10e31a9a 18/11/30 11:37:46 INFO zookeeper.ClientCnxn: Opening socket connection to server realtime-2/10.1.1.3:2181. Will not attempt to authenticate using SASL (unknown error) 18/11/30 11:37:47 INFO zookeeper.ClientCnxn: Socket connection established to realtime-2/10.1.1.3:2181, initiating session 18/11/30 11:37:47 INFO zookeeper.ClientCnxn: Session establishment complete on server realtime-2/10.1.1.3:2181, sessionid = 0x2675e9a37a90000, negotiated timeout = 5000 18/11/30 11:37:47 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/HDFScluster in ZK. 18/11/30 11:37:47 INFO ha.ActiveStandbyElector: Session connected. 18/11/30 11:37:47 INFO zookeeper.ZooKeeper: Session: 0x2675e9a37a90000 closed 18/11/30 11:37:47 INFO zookeeper.ClientCnxn: EventThread shut down [root@realtime-1 ~]# 9 Hadoop集群启动运行 我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行\n步骤1. 启动HDFS相关服务 通过下面的命令可以启动HDFS相关服务： start-dfs.sh 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# start-dfs.sh 18/11/30 11:55:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Starting namenodes on [realtime-2 realtime-1] realtime-2: starting namenode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-namenode-realtime-2.out realtime-1: starting namenode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-namenode-realtime-1.out realtime-1: starting datanode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-datanode-realtime-1.out realtime-2: starting datanode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-datanode-realtime-2.out realtime-3: starting datanode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-datanode-realtime-3.out Starting journal nodes [realtime-1 realtime-2 realtime-3] realtime-1: starting journalnode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-journalnode-realtime-1.out realtime-2: starting journalnode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-journalnode-realtime-2.out realtime-3: starting journalnode, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-journalnode-realtime-3.out 18/11/30 11:56:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Starting ZK Failover Controllers on NN hosts [realtime-2 realtime-1] realtime-2: starting zkfc, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-zkfc-realtime-2.out realtime-1: starting zkfc, logging to /usr/cx/hadoop-2.7.1/logs/hadoop-root-zkfc-realtime-1.out [root@realtime-1 ~]# 通过下面的命令查看节点1中对应的相关服务： jps ssh realtime-2 \"jps\" ssh realtime-3 \"jps\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# jps 10033 ResourceManager 9427 DataNode 9315 NameNode 2597 QuorumPeerMain 10457 Jps 9625 JournalNode 9818 DFSZKFailoverController 10140 NodeManager 1743 VmServer.jar [root@realtime-1 ~]# 通过下面的命令在节点2中启动ResourceManager进程：\nssh realtime-2 \"yarn-daemon.sh start resourcemanager\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh realtime-2 \"yarn-daemon.sh start resourcemanager\" starting resourcemanager, logging to /usr/cx/hadoop-2.7.1/logs/yarn-root-resourcemanager-realtime-2.out [root@realtime-1 ~]# 通过下面的命令查看节点2中对应的相关服务：\nssh realtime-2 \"jps\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh realtime-2 \"jps\" 5792 DataNode 6164 NameNode 1703 VmServer.jar 6779 ResourceManager 6428 NodeManager 5981 DFSZKFailoverController 6846 Jps 2686 QuorumPeerMain 5887 JournalNode [root@realtime-1 ~]# 由返回结果可以看出，此时在节点2中已经成功启动了ResourceManager进程\n10 Hadoop 高可用性测试 笔者在写作过程中是在节点1中进行下面的操作，同学们可以在任意节点中进行下面的操作，所实现的效果是一致的\n步骤1. NodeManager状态查看 由于设置了2个NameNode，因此必然会有一个处于Active状态，一个处于StandBy状态，至于具体哪个节点处于Active状态，需要根据实际情况确定，并不是千篇一律的。\n当Hadoop成功启动后，我们打开浏览器，输入网址http://realtime-1:50070便可以访问HDFS的Web管理页面（此时可以看到realtime-1节点是处于active状态的）： 输入网址http://realtime-2:50070依然可以访问HDFS的Web管理页面（此时可以看到realtime-2节点是处于standby状态的）： 步骤2. ResourceManager状态查看 由于设置了2个ResourceManager，因此必然会有一个处于Active状态，一个处于StandBy状态，至于具体哪个节点处于Active状态，需要根据实际情况确定，并不是千篇一律的。\n在终端模拟器中，通过下面的命令可以查看逻辑ID为rm1（实际映射的节点为realtime-1）的节点对应的ResourceManager状态： yarn rmadmin -getServiceState rm1 命令运行后的返回结果如下所示（可见当前节点是active状态）：\n[root@realtime-1 ~]# yarn rmadmin -getServiceState rm1 18/11/30 16:35:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable active [root@realtime-1 ~]# 在终端模拟器中，通过下面的命令可以查看逻辑ID为rm2（实际映射的节点为realtime-2）的节点对应的ResourceManager状态： yarn rmadmin -getServiceState rm2 命令运行后的返回结果如下所示（可见当前节点是standby状态）：\n[root@realtime-1 ~]# yarn rmadmin -getServiceState rm2 18/11/30 16:35:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable standby [root@realtime-1 ~]# 步骤3. HDFS高可用测试 通过下面的命令在HDFS中创建测试文件夹/test： hadoop fs -mkdir /test 通过下面的命令查看HDFS中创建的测试文件夹/test： hadoop fs -ls / 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# hadoop fs -ls / 18/11/30 16:40:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Found 1 items drwxr-xr-x - root supergroup 0 2018-11-30 16:39 /test [root@realtime-1 ~]# 由返回结果可以看出，此时依然可以成功查询HDFS文件信息\n打开浏览器，输入网址http://realtime-2:50070访问HDFS的Web管理页面，此时可以看到realtime-2节点已经成功接替成为NameNode并处于active状态（同学们需要根据实际情况来确定）：\n步骤4. YARN高可用测试 通过下面的命令，使用Hadoop自带的案例测试MapReduce应用程序的运行： hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output 18/11/30 16:47:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 18/11/30 16:47:15 INFO input.FileInputFormat: Total input paths to process : 0 18/11/30 16:47:15 INFO mapreduce.JobSubmitter: number of splits:0 18/11/30 16:47:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1543557487449_0001 18/11/30 16:47:16 INFO impl.YarnClientImpl: Submitted application application_1543557487449_0001 18/11/30 16:47:16 INFO mapreduce.Job: The url to track the job: http://realtime-1:8089/proxy/application_1543557487449_0001/ 18/11/30 16:47:16 INFO mapreduce.Job: Running job: job_1543557487449_0001 18/11/30 16:47:26 INFO mapreduce.Job: Job job_1543557487449_0001 running in uber mode : false 18/11/30 16:47:26 INFO mapreduce.Job: map 0% reduce 0% 18/11/30 16:47:37 INFO mapreduce.Job: map 0% reduce 100% 18/11/30 16:47:38 INFO mapreduce.Job: Job job_1543557487449_0001 completed successfully 18/11/30 16:47:39 INFO mapreduce.Job: Counters: 38 File System Counters FILE: Number of bytes read=0 FILE: Number of bytes written=119357 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 HDFS: Number of bytes read=0 HDFS: Number of bytes written=0 HDFS: Number of read operations=3 HDFS: Number of large read operations=0 HDFS: Number of write operations=2 Job Counters Launched reduce tasks=1 Total time spent by all maps in occupied slots (ms)=0 Total time spent by all reduces in occupied slots (ms)=227232 Total time spent by all reduce tasks (ms)=7101 Total vcore-seconds taken by all reduce tasks=7101 Total megabyte-seconds taken by all reduce tasks=7271424 Map-Reduce Framework Combine input records=0 Combine output records=0 Reduce input groups=0 Reduce shuffle bytes=0 Reduce input records=0 Reduce output records=0 Spilled Records=0 Shuffled Maps =0 Failed Shuffles=0 Merged Map outputs=0 GC time elapsed (ms)=67 CPU time spent (ms)=290 Physical memory (bytes) snapshot=94629888 Virtual memory (bytes) snapshot=2064699392 Total committed heap usage (bytes)=30474240 Shuffle Errors BAD_ID=0 CONNECTION=0 IO_ERROR=0 WRONG_LENGTH=0 WRONG_MAP=0 WRONG_REDUCE=0 File Output Format Counters Bytes Written=0 [root@realtime-1 ~]# 通过下面的命令停止Active状态节点对应的ResourceManager进程（笔者写作过程中对应的为realtime-1节点，同学们需要根据实际情况来确定） ssh realtime-1 \"yarn-daemon.sh stop resourcemanager\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh realtime-1 \"yarn-daemon.sh stop resourcemanager\" stopping resourcemanager [root@realtime-1 ~]# 通过下面的命令查看对应节点的进程信息： ssh realtime-1 \"jps\" 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# ssh realtime-1 \"jps\" 9427 DataNode 2597 QuorumPeerMain 9625 JournalNode 9818 DFSZKFailoverController 10140 NodeManager 11885 Jps 1743 VmServer.jar [root@realtime-1 ~]# 由返回结果可以看出，ResourceManager进程已经被停止\n通过下面的命令，再次使用Hadoop自带的案例测试MapReduce应用程序的运行： hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output1 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output1 18/11/30 16:50:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 18/11/30 16:50:31 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm2 18/11/30 16:50:32 INFO input.FileInputFormat: Total input paths to process : 0 18/11/30 16:50:32 INFO mapreduce.JobSubmitter: number of splits:0 18/11/30 16:50:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1543567750404_0001 18/11/30 16:50:33 INFO impl.YarnClientImpl: Submitted application application_1543567750404_0001 18/11/30 16:50:33 INFO mapreduce.Job: The url to track the job: http://realtime-2:8089/proxy/application_1543567750404_0001/ 18/11/30 16:50:33 INFO mapreduce.Job: Running job: job_1543567750404_0001 18/11/30 16:50:45 INFO mapreduce.Job: Job job_1543567750404_0001 running in uber mode : false 18/11/30 16:50:45 INFO mapreduce.Job: map 0% reduce 0% 18/11/30 16:50:53 INFO mapreduce.Job: map 0% reduce 100% 18/11/30 16:50:54 INFO mapreduce.Job: Job job_1543567750404_0001 completed successfully 18/11/30 16:50:54 INFO mapreduce.Job: Counters: 38 File System Counters FILE: Number of bytes read=0 FILE: Number of bytes written=119358 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 HDFS: Number of bytes read=0 HDFS: Number of bytes written=0 HDFS: Number of read operations=3 HDFS: Number of large read operations=0 HDFS: Number of write operations=2 Job Counters Launched reduce tasks=1 Total time spent by all maps in occupied slots (ms)=0 Total time spent by all reduces in occupied slots (ms)=147936 Total time spent by all reduce tasks (ms)=4623 Total vcore-seconds taken by all reduce tasks=4623 Total megabyte-seconds taken by all reduce tasks=4733952 Map-Reduce Framework Combine input records=0 Combine output records=0 Reduce input groups=0 Reduce shuffle bytes=0 Reduce input records=0 Reduce output records=0 Spilled Records=0 Shuffled Maps =0 Failed Shuffles=0 Merged Map outputs=0 GC time elapsed (ms)=81 CPU time spent (ms)=280 Physical memory (bytes) snapshot=94146560 Virtual memory (bytes) snapshot=2064695296 Total committed heap usage (bytes)=30474240 Shuffle Errors BAD_ID=0 CONNECTION=0 IO_ERROR=0 WRONG_LENGTH=0 WRONG_MAP=0 WRONG_REDUCE=0 File Output Format Counters Bytes Written=0 [root@realtime-1 ~]# 由返回结果可以看出，此时YARN依然可以可靠的实现任务的调度\n在终端模拟器中，通过下面的命令可以查看逻辑ID为rm2（实际映射的节点为realtime-2）的节点对应的ResourceManager状态（同学们需要根据实际情况来确定）： yarn rmadmin -getServiceState rm2 命令运行后的返回结果如下所示：\n[root@realtime-1 ~]# yarn rmadmin -getServiceState rm2 18/11/30 16:51:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable active [root@realtime-1 ~]# 由返回结果可以看出，当前节点已经自动成功接替变成了active状态\n","wordCount":"15679","inLanguage":"zh-cn","datePublished":"2022-10-10T16:04:23+08:00","dateModified":"2022-12-10T16:04:23+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://waite.wang/posts/bigdata/hadoop-group-install-and-config/"},"publisher":{"@type":"Organization","name":"隶笔难书","logo":{"@type":"ImageObject","url":"https://waite.wang/images/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://waite.wang/ accesskey=h title="隶笔难书 (Alt + H)">隶笔难书</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://waite.wang/ title=首页><span>首页</span></a></li><li><a href=https://waite.wang/search title=搜索><span>搜索</span></a></li><li><a href=https://waite.wang/categories title=分类><span>分类</span></a></li><li><a href=https://waite.wang/tags title=标签><span>标签</span></a></li><li><a href=https://waite.wang/archives title=归档><span>归档</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">hadoop集群的安装与配置</h1><div class=post-description>hadoop集群的安装与配置</div><div class=post-meta>Created: &nbsp;<span title='2022-10-10 16:04:23 +0800 +0800'>2022-10-10</span>&nbsp;·&nbsp;32 min&nbsp;·&nbsp;15679 words&nbsp;|&nbsp;<a href=https://github.com/Waite0603/HugoBlog/edit/main/content/posts/bigData/hadoop-group-install-and-config.md rel="noopener noreferrer" target=_blank>在 GitHub 编辑</a>
&nbsp; | Last Updated:&nbsp;2022-12-10</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#hadoop%e5%9f%ba%e7%a1%80 aria-label=Hadoop基础>Hadoop基础</a><ul><ul><li><a href=#1-%e5%ae%9e%e9%aa%8c%e7%9b%ae%e7%9a%84 aria-label="1 、实验目的">1 、实验目的</a></li><li><a href=#2%e5%ae%9e%e9%aa%8c%e5%8e%9f%e7%90%86 aria-label=2、实验原理>2、实验原理</a></li></ul><li><a href=#1-%e9%9b%86%e7%be%a4%e8%8a%82%e7%82%b9%e5%9f%ba%e6%9c%ac%e9%85%8d%e7%bd%ae aria-label="1 集群节点基本配置">1 集群节点基本配置</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-%e8%8a%82%e7%82%b9ip%e5%9c%b0%e5%9d%80%e6%9f%a5%e8%af%a2 aria-label="步骤1. 节点IP地址查询">步骤1. 节点IP地址查询</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-%e8%8a%82%e7%82%b9%e4%b8%bb%e6%9c%ba%e5%90%8d%e9%85%8d%e7%bd%ae aria-label="步骤2. 节点主机名配置">步骤2. 节点主机名配置</a></li><li><a href=#%e6%ad%a5%e9%aa%a43-%e8%8a%82%e7%82%b9123%e4%b8%bb%e6%9c%ba%e5%90%8d%e4%b8%8eip%e5%9c%b0%e5%9d%80%e6%98%a0%e5%b0%84%e6%96%87%e4%bb%b6%e9%85%8d%e7%bd%ae aria-label="步骤3. 节点1、2、3主机名与IP地址映射文件配置">步骤3. 节点1、2、3主机名与IP地址映射文件配置</a></li></ul></li><li><a href=#2-%e9%85%8d%e7%bd%aessh%e5%85%8d%e5%af%86%e7%a0%81%e7%99%bb%e5%bd%95 aria-label="2 配置SSH免密码登录">2 配置SSH免密码登录</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-%e8%8a%82%e7%82%b9123%e7%a7%98%e9%92%a5%e9%85%8d%e7%bd%ae%e5%8f%8a%e5%88%86%e5%8f%91 aria-label="步骤1. 节点1、2、3秘钥配置及分发">步骤1. 节点1、2、3秘钥配置及分发</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-ssh%e5%85%8d%e5%af%86%e7%a0%81%e7%99%bb%e5%bd%95%e6%b5%8b%e8%af%95 aria-label="步骤2. SSH免密码登录测试">步骤2. SSH免密码登录测试</a></li></ul></li><li><a href=#3-%e5%ae%89%e8%a3%85%e9%85%8d%e7%bd%aejdk18 aria-label="3 安装配置JDK1.8">3 安装配置JDK1.8</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-%e5%88%9b%e5%bb%ba%e5%b7%a5%e4%bd%9c%e8%b7%af%e5%be%84 aria-label="步骤1. 创建工作路径">步骤1. 创建工作路径</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-%e8%a7%a3%e5%8e%8b%e5%ae%89%e8%a3%85%e5%8c%85 aria-label="步骤2. 解压安装包">步骤2. 解压安装包</a></li><li><a href=#%e6%ad%a5%e9%aa%a43-%e9%85%8d%e7%bd%ae%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label="步骤3. 配置环境变量">步骤3. 配置环境变量</a></li><li><a href=#%e6%ad%a5%e9%aa%a44-%e6%9b%b4%e6%96%b0%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label="步骤4. 更新环境变量">步骤4. 更新环境变量</a></li><li><a href=#%e6%ad%a5%e9%aa%a45-%e9%aa%8c%e8%af%81jdk%e6%98%af%e5%90%a6%e9%85%8d%e7%bd%ae%e6%88%90%e5%8a%9f aria-label="步骤5. 验证JDK是否配置成功">步骤5. 验证JDK是否配置成功</a></li></ul></li><li><a href=#4-ntp%e6%9c%8d%e5%8a%a1%e9%85%8d%e7%bd%ae aria-label="4 NTP服务配置">4 NTP服务配置</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-ntp%e6%9c%8d%e5%8a%a1%e9%85%8d%e7%bd%ae aria-label="步骤1. NTP服务配置">步骤1. NTP服务配置</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-%e5%90%af%e5%8a%a8ntp%e6%9c%8d%e5%8a%a1 aria-label="步骤2. 启动NTP服务">步骤2. 启动NTP服务</a></li><li><a href=#%e6%ad%a5%e9%aa%a43-ntp%e6%9c%8d%e5%8a%a1%e7%8a%b6%e6%80%81%e6%9f%a5%e7%9c%8b aria-label="步骤3. NTP服务状态查看">步骤3. NTP服务状态查看</a></li></ul></li><li><a href=#5-selinux%e5%ae%89%e5%85%a8%e9%85%8d%e7%bd%ae aria-label="5 SElinux安全配置">5 SElinux安全配置</a></li><li><a href=#6-%e5%ae%89%e8%a3%85%e9%85%8d%e7%bd%aezookeeper%e9%9b%86%e7%be%a4 aria-label="6 安装配置ZooKeeper集群">6 安装配置ZooKeeper集群</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-%e8%a7%a3%e5%8e%8b%e5%ae%89%e8%a3%85%e5%8c%85 aria-label="步骤1. 解压安装包">步骤1. 解压安装包</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e7%9b%ae%e5%bd%95%e5%88%9b%e5%bb%ba aria-label="步骤2. 数据存储目录创建">步骤2. 数据存储目录创建</a></li><li><a href=#%e6%ad%a5%e9%aa%a43-%e4%b8%bb%e6%9c%bamyid%e7%bc%96%e5%8f%b7%e6%96%87%e4%bb%b6%e5%88%9b%e5%bb%ba aria-label="步骤3. 主机myid编号文件创建">步骤3. 主机myid编号文件创建</a></li><li><a href=#%e6%ad%a5%e9%aa%a44-zookeeper%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6%e7%bc%96%e8%be%91 aria-label="步骤4. ZooKeeper配置文件编辑">步骤4. ZooKeeper配置文件编辑</a></li><li><a href=#%e6%ad%a5%e9%aa%a45-%e6%96%87%e4%bb%b6%e5%88%86%e5%8f%91 aria-label="步骤5. 文件分发">步骤5. 文件分发</a></li><li><a href=#%e6%ad%a5%e9%aa%a46-zookeeper%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f%e9%85%8d%e7%bd%ae aria-label="步骤6. ZooKeeper环境变量配置">步骤6. ZooKeeper环境变量配置</a></li><li><a href=#%e6%ad%a5%e9%aa%a47-%e6%9b%b4%e6%96%b0%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label="步骤7. 更新环境变量">步骤7. 更新环境变量</a></li><li><a href=#%e6%ad%a5%e9%aa%a48-%e9%aa%8c%e8%af%81%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f%e6%98%af%e5%90%a6%e9%85%8d%e7%bd%ae%e6%88%90%e5%8a%9f aria-label="步骤8. 验证环境变量是否配置成功">步骤8. 验证环境变量是否配置成功</a></li></ul></li><li><a href=#7-zookeeper%e5%90%af%e5%8a%a8%e5%8f%8a%e7%8a%b6%e6%80%81%e6%9f%a5%e7%9c%8b aria-label="7 ZooKeeper启动及状态查看">7 ZooKeeper启动及状态查看</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-zookeeper%e5%90%af%e5%8a%a8 aria-label="步骤1. ZooKeeper启动">步骤1. ZooKeeper启动</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-zookeeper%e8%bf%90%e8%a1%8c%e7%8a%b6%e6%80%81%e6%9f%a5%e7%9c%8b aria-label="步骤2. ZooKeeper运行状态查看">步骤2. ZooKeeper运行状态查看</a></li></ul></li><li><a href=#8-%e5%ae%89%e8%a3%85%e9%85%8d%e7%bd%aehadoop%e9%9b%86%e7%be%a4 aria-label="8 安装配置Hadoop集群">8 安装配置Hadoop集群</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e7%9b%ae%e5%bd%95%e5%88%9b%e5%bb%ba aria-label="步骤1. 数据存储目录创建">步骤1. 数据存储目录创建</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-%e8%a7%a3%e5%8e%8b%e5%ae%89%e8%a3%85%e6%96%87%e4%bb%b6 aria-label="步骤2. 解压安装文件">步骤2. 解压安装文件</a></li><li><a href=#%e6%ad%a5%e9%aa%a43-%e7%bc%96%e8%be%91hadoop%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label="步骤3. 编辑Hadoop配置文件：">步骤3. 编辑Hadoop配置文件：</a></li><li><a href=#%e6%ad%a5%e9%aa%a44-%e6%96%87%e4%bb%b6%e5%88%86%e5%8f%91 aria-label="步骤4. 文件分发">步骤4. 文件分发</a></li><li><a href=#%e6%ad%a5%e9%aa%a45-%e9%85%8d%e7%bd%aehadoop%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label="步骤5. 配置Hadoop环境变量">步骤5. 配置Hadoop环境变量</a></li><li><a href=#%e6%ad%a5%e9%aa%a46-%e6%9b%b4%e6%96%b0%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f aria-label="步骤6. 更新环境变量">步骤6. 更新环境变量</a></li><li><a href=#%e6%ad%a5%e9%aa%a47-%e9%aa%8c%e8%af%81hadoop%e7%8e%af%e5%a2%83%e5%8f%98%e9%87%8f%e6%98%af%e5%90%a6%e9%85%8d%e7%bd%ae%e6%88%90%e5%8a%9f aria-label="步骤7. 验证Hadoop环境变量是否配置成功">步骤7. 验证Hadoop环境变量是否配置成功</a></li><li><a href=#%e6%ad%a5%e9%aa%a48-%e6%a0%bc%e5%bc%8f%e5%8c%96hdfs aria-label="步骤8. 格式化HDFS">步骤8. 格式化HDFS</a></li><li><a href=#%e6%ad%a5%e9%aa%a49-%e6%a0%bc%e5%bc%8f%e5%8c%96zkfc%e5%85%83%e6%95%b0%e6%8d%ae aria-label="步骤9. 格式化zkfc元数据">步骤9. 格式化zkfc元数据</a></li></ul></li><li><a href=#9-hadoop%e9%9b%86%e7%be%a4%e5%90%af%e5%8a%a8%e8%bf%90%e8%a1%8c aria-label="9 Hadoop集群启动运行">9 Hadoop集群启动运行</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-%e5%90%af%e5%8a%a8hdfs%e7%9b%b8%e5%85%b3%e6%9c%8d%e5%8a%a1 aria-label="步骤1. 启动HDFS相关服务">步骤1. 启动HDFS相关服务</a></li></ul></li><li><a href=#10-hadoop-%e9%ab%98%e5%8f%af%e7%94%a8%e6%80%a7%e6%b5%8b%e8%af%95 aria-label="10 Hadoop 高可用性测试">10 Hadoop 高可用性测试</a><ul><li><a href=#%e6%ad%a5%e9%aa%a41-nodemanager%e7%8a%b6%e6%80%81%e6%9f%a5%e7%9c%8b aria-label="步骤1. NodeManager状态查看">步骤1. NodeManager状态查看</a></li><li><a href=#%e6%ad%a5%e9%aa%a42-resourcemanager%e7%8a%b6%e6%80%81%e6%9f%a5%e7%9c%8b aria-label="步骤2. ResourceManager状态查看">步骤2. ResourceManager状态查看</a></li><li><a href=#%e6%ad%a5%e9%aa%a43-hdfs%e9%ab%98%e5%8f%af%e7%94%a8%e6%b5%8b%e8%af%95 aria-label="步骤3. HDFS高可用测试">步骤3. HDFS高可用测试</a></li><li><a href=#%e6%ad%a5%e9%aa%a44-yarn%e9%ab%98%e5%8f%af%e7%94%a8%e6%b5%8b%e8%af%95 aria-label="步骤4. YARN高可用测试">步骤4. YARN高可用测试</a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=hadoop基础>Hadoop基础<a hidden class=anchor aria-hidden=true href=#hadoop基础>#</a></h1><h3 id=1-实验目的>1 、实验目的<a hidden class=anchor aria-hidden=true href=#1-实验目的>#</a></h3><p>通过本节实验的学习，同学们可以掌握Hadoop集群环境部署与配置。本实验完成后，要求学生掌握以下内容：</p><ol><li><p>掌握集群所有节点之间SSH免密登录配置方式；</p></li><li><p>掌握NTP服务配置，实现节点间的时间同步；</p></li><li><p>掌握ZooKeeper集群的搭建方式；</p></li><li><p>掌握Hadoop集群的搭建配置流程；</p></li><li><p>理解Hadoop集群的高可用（HA）原理，并掌握Hadoop集群的高可用（HA）配置方法。</p></li></ol><h3 id=2实验原理>2、实验原理<a hidden class=anchor aria-hidden=true href=#2实验原理>#</a></h3><p>需要按照以下流程，在Linux上进行Hadoop集群的安装部署：</p><ol><li><p>主机名配置：在大型的Hadoop集群中，往往由成百上千个节点组成，如果通过IP地址对不同节点进行管理，那么集群维护的工作量将会十分繁重，因此在工程环境中，常常通过对每个节点设置唯一的主机名，从而实现对节点进行管理。</p></li><li><p>SSH（安全外壳协议）免密码登录配置：推荐安装OpenSSH。Hadoop需要通过SSH来启动Slave列表中各台主机的守护进程，因此SSH也是必须安装的。</p></li><li><p>安装配置JDK1.7（或更高版本）：Hadoop是用Java编写的程序，Hadoop的编译及MapReduce的运行都需要使用JDK，因此在安装Hadoop前，必须安装JDK1.7或更高版本。</p></li><li><p>NTP服务配置：本实验需要在实现Hadoop集群搭建的同时，并进行高可用性（HA）的配置，因此需要通过ZooKeeper来对集群中的节点进行协调，而ZooKeeper需要保证节点间的时钟相互一致，因此需要在集群中配置NTP服务。</p></li><li><p>SElinux安全配置：CentOS默认启用了SElinux，在网络服务方面权限要求比较严格，因此需要对SElinux安全配置进行更改。</p></li><li><p>ZooKeeper集群搭建：高可用性（HA）Hadoop集群的搭建需要依赖于ZooKeeper来对集群中的节点进行协调，因此需要进行ZooKeeper集群搭建。</p></li><li><p>Hadoop核心配置。Hadoop的稳定运行需要依赖于其核心配置文件，因此当上述准备工作就绪后，我们便需要着重进行配置文件编写来实现Hadoop的可靠运行。</p></li></ol><p>我们需要在<code>节点1</code>、<code>节点2</code>、<code>节点3</code>中进行高可用Hadoop集群环境的部署。各个节点所部署的服务如下所示：</p><table><thead><tr><th>节点1</th><th>节点2</th><th>节点3</th></tr></thead><tbody><tr><td>NameNode</td><td>StandBy</td><td></td></tr><tr><td>ResourceManager</td><td>StandBy</td><td></td></tr><tr><td>DFSZKFailoverController</td><td>DFSZKFailoverController</td><td></td></tr><tr><td>DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>NodeManager</td><td>NodeManager</td><td>NodeManager</td></tr><tr><td>JournalNode</td><td>JournalNode</td><td>JournalNode</td></tr></tbody></table><h2 id=1-集群节点基本配置>1 集群节点基本配置<a hidden class=anchor aria-hidden=true href=#1-集群节点基本配置>#</a></h2><h3 id=步骤1-节点ip地址查询>步骤1. 节点IP地址查询<a hidden class=anchor aria-hidden=true href=#步骤1-节点ip地址查询>#</a></h3><ol><li>在<code>节点1、2、3</code>中通过下面的命令查询节点IP地址：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ifconfig
</span></span></code></pre></div><p>命令运行后的返回结果如下所示 (每台虚拟机的IP地址都是不同的，因此需要以实际地址信息为准）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@CentOS6 ~]# ifconfig
</span></span><span class=line><span class=cl>eth6      Link encap:Ethernet  HWaddr 02:00:1E:79:09:04 
</span></span><span class=line><span class=cl>          inet addr:10.1.1.4  Bcast:10.1.1.255  Mask:255.255.255.0
</span></span><span class=line><span class=cl>          inet6 addr: fe80::1eff:fe79:904/64 Scope:Link
</span></span><span class=line><span class=cl>          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
</span></span><span class=line><span class=cl>          RX packets:20832 errors:0 dropped:0 overruns:0 frame:0
</span></span><span class=line><span class=cl>          TX packets:13052 errors:0 dropped:0 overruns:0 carrier:0
</span></span><span class=line><span class=cl>          collisions:0 txqueuelen:1000
</span></span><span class=line><span class=cl>          RX bytes:31392026 (29.9 MiB)  TX bytes:929956 (908.1 KiB)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>lo        Link encap:Local Loopback 
</span></span><span class=line><span class=cl>          inet addr:127.0.0.1  Mask:255.0.0.0
</span></span><span class=line><span class=cl>          inet6 addr: ::1/128 Scope:Host
</span></span><span class=line><span class=cl>          UP LOOPBACK RUNNING  MTU:16436  Metric:1
</span></span><span class=line><span class=cl>          RX packets:12 errors:0 dropped:0 overruns:0 frame:0
</span></span><span class=line><span class=cl>          TX packets:12 errors:0 dropped:0 overruns:0 carrier:0
</span></span><span class=line><span class=cl>          collisions:0 txqueuelen:0
</span></span><span class=line><span class=cl>          RX bytes:720 (720.0 b)  TX bytes:720 (720.0 b) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[root@CentOS6 ~]#
</span></span></code></pre></div><p>需要记录三个节点的IP地址，在后文中我们需要根据此IP地址进行相关操作</p><h3 id=步骤2-节点主机名配置>步骤2. 节点主机名配置<a hidden class=anchor aria-hidden=true href=#步骤2-节点主机名配置>#</a></h3><p>需要在<code>节点1、2、3</code>进行下列操作，将三个主机名分别配置为realtime-1，realtime-2，realtime-3</p><ol><li>通过下列命令使用vi编辑器编辑主机名配置文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /etc/sysconfig/network
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>NETWORKING=yes
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>HOSTNAME=CentOS6.5                            (注：需要将此行内容修改为实际的主机名realtime-1、realtime-2、realtime-3)
</span></span></code></pre></div><ol start=2><li>在文件中进行内容更改，将HOSTNAME字段内容配置成realtime-：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>HOSTNAME=realtime-1
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><p>更改后的文件内容如下所示：</p><ol start=3><li>更改后的内容会在下次系统重启的时候生效，通过下列命令重新启动系统：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>reboot
</span></span></code></pre></div><h3 id=步骤3-节点123主机名与ip地址映射文件配置>步骤3. 节点1、2、3主机名与IP地址映射文件配置<a hidden class=anchor aria-hidden=true href=#步骤3-节点123主机名与ip地址映射文件配置>#</a></h3><ol><li>在<code>节点1、2、3</code>中，通过下列命令使用vi编辑器编辑hosts文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /etc/hosts
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 (注：在此行增加内容)
</span></span><span class=line><span class=cl>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
</span></span></code></pre></div><ol start=2><li>增加节点<code>1、2、3</code>的IP地址与主机名的映射关系、节点间的IP地址与主机名的映射关系、节点间的IP地址与主机名的映射关系，IP地址与主机名之间用空格分隔（主机名填写为前文配置的节点实际主机名称，IP地址需要根据上文中的查询结果来进行填写，并与实际的主机名相对应）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>10.1.1.4 realtime-1
</span></span><span class=line><span class=cl>10.1.1.3 realtime-2
</span></span><span class=line><span class=cl>10.1.1.206 realtime-3
</span></span></code></pre></div><p>更改后的文件内容如下所示</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
</span></span><span class=line><span class=cl>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
</span></span><span class=line><span class=cl>10.1.1.4 realtime-1
</span></span><span class=line><span class=cl>10.1.1.3 realtime-2
</span></span><span class=line><span class=cl>10.1.1.206 realtime-3
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><ol start=3><li>通过下列命令检测主机名与IP映射是否配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ping realtime-1 -c 2
</span></span></code></pre></div><p>如果配置成功，则会显示如下结果：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ping realtime-1 -c 2      (注：通过此命令向realtime-1节点发送2个报文)
</span></span><span class=line><span class=cl>PING realtime-1 (10.1.1.4) 56(84) bytes of data.
</span></span><span class=line><span class=cl>64 bytes from realtime-1 (10.1.1.4): icmp_seq=1 ttl=64 time=1.98 ms
</span></span><span class=line><span class=cl>64 bytes from realtime-1 (10.1.1.4): icmp_seq=2 ttl=64 time=0.341 ms
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>--- realtime-1 ping statistics ---
</span></span><span class=line><span class=cl>2 packets transmitted, 2 received, 0% packet loss, time 1001ms
</span></span><span class=line><span class=cl>rtt min/avg/max/mdev = 0.341/1.163/1.985/0.822 ms
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=4><li>通过下列命令检测主机名与IP映射是否配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ping realtime-2 -c 2
</span></span></code></pre></div><p>如果配置成功，则会显示如下结果：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ping realtime-2 -c 2     (注：通过此命令向realtime-2节点发送2个报文)
</span></span><span class=line><span class=cl>PING realtime-2 (10.1.1.3) 56(84) bytes of data.
</span></span><span class=line><span class=cl>64 bytes from realtime-2 (10.1.1.3): icmp_seq=1 ttl=64 time=0.047 ms
</span></span><span class=line><span class=cl>64 bytes from realtime-2 (10.1.1.3): icmp_seq=2 ttl=64 time=0.026 ms
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>--- realtime-2 ping statistics ---
</span></span><span class=line><span class=cl>2 packets transmitted, 2 received, 0% packet loss, time 999ms
</span></span><span class=line><span class=cl>rtt min/avg/max/mdev = 0.026/0.036/0.047/0.012 ms
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=5><li>通过下列命令检测主机名与IP映射是否配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ping realtime-3 -c 2
</span></span></code></pre></div><p>如果配置成功，则会显示如下结果：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ping realtime-3 -c 2    (注：通过此命令向realtime-3节点发送2个报文)
</span></span><span class=line><span class=cl>PING realtime-3 (10.1.1.206) 56(84) bytes of data.
</span></span><span class=line><span class=cl>64 bytes from realtime-3 (10.1.1.206): icmp_seq=1 ttl=64 time=1.36 ms
</span></span><span class=line><span class=cl>64 bytes from realtime-3 (10.1.1.206): icmp_seq=2 ttl=64 time=0.315 ms
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>--- realtime-3 ping statistics ---
</span></span><span class=line><span class=cl>2 packets transmitted, 2 received, 0% packet loss, time 1002ms
</span></span><span class=line><span class=cl>rtt min/avg/max/mdev = 0.315/0.841/1.367/0.526 ms
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p><em>如果无法进行正常的报文发送，请检查主机名是否配置正确，同时请检查主机名与IP地址映射是否配置正确。</em></p><h2 id=2-配置ssh免密码登录>2 配置SSH免密码登录<a hidden class=anchor aria-hidden=true href=#2-配置ssh免密码登录>#</a></h2><h3 id=步骤1-节点123秘钥配置及分发>步骤1. 节点1、2、3秘钥配置及分发<a hidden class=anchor aria-hidden=true href=#步骤1-节点123秘钥配置及分发>#</a></h3><p>例如<code>节点1</code> : 需要在节点1进行下列操作，在节点1中生成秘钥文件，然后将公钥文件分发到节点2和节点3中，实现在节点1可以免密码登录到集群中的其他主机中。</p><ol><li>通过下面的命令生成密钥（使用rsa加密方式）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>echo -e &#34;\n&#34;|ssh-keygen -t rsa -N &#34;&#34; &gt;/dev/null 2&gt;&amp;1
</span></span></code></pre></div><p>默认情况下会在~/.ssh/文件夹下生成公钥文件id_rsa.pub和私钥文件id_rsa，通过下面的命令对~/.ssh/内容进行查看：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ll ~/.ssh/
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ll ~/.ssh/
</span></span><span class=line><span class=cl>总用量 8
</span></span><span class=line><span class=cl>-rw-------. 1 root root 1675 11月 29 13:42 id_rsa
</span></span><span class=line><span class=cl>-rw-r--r--. 1 root root  397 11月 29 13:42 id_rsa.pub
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=2><li>通过下面的命令将公钥文件发送到本机以及其他两个节点，创建root免密钥通道（需要输入密码：111111）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh-copy-id -i /root/.ssh/id_rsa.pub root@realtime-1 # 其他的节点需要随之改动root@realtime-2 and root@realtime-3
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub root@realtime-1
</span></span><span class=line><span class=cl>The authenticity of host &#39;realtime-1 (10.1.1.4)&#39; can&#39;t be established.
</span></span><span class=line><span class=cl>RSA key fingerprint is 9f:3b:30:10:65:46:c9:c3:2b:fb:e5:28:38:39:9c:84.
</span></span><span class=line><span class=cl>Are you sure you want to continue connecting (yes/no)? yes    (注：此处需要输入yes)
</span></span><span class=line><span class=cl>Warning: Permanently added &#39;realtime-1,10.1.1.4&#39; (RSA) to the list of known hosts.
</span></span><span class=line><span class=cl>root@realtime-1&#39;s password:                      （注：此处需要输入root用户密码，为111111）
</span></span><span class=line><span class=cl>Now try logging into the machine, with &#34;ssh &#39;root@realtime-1&#39;&#34;, and check in:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  .ssh/authorized_keys
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>to make sure we haven&#39;t added extra keys that you weren&#39;t expecting.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤2-ssh免密码登录测试>步骤2. SSH免密码登录测试<a hidden class=anchor aria-hidden=true href=#步骤2-ssh免密码登录测试>#</a></h3><p>集群中各个节点秘钥分发完毕后，可以通过ssh远程登录命令来测试免密码登录是否配置成功。为了操作统一，我们在节点3中进行下面的操作（在其他节点操作所实现的效果也是一样的）</p><ol><li>在节点3中通过下面的命令可以实现免密码远程登录到节点1：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-1 #依次运行realtime-2 and realtime-3
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-3 ~]# ssh realtime-1
</span></span><span class=line><span class=cl>Last login: Thu Nov 29 14:08:34 2018 from realtime-3
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>如果从源主机到目的主机的登录过程中，出现需要输入密码的情况，那么需要检查是否已经成功将源主机的公钥文件发送到目的主机中</p><h2 id=3-安装配置jdk18>3 安装配置JDK1.8<a hidden class=anchor aria-hidden=true href=#3-安装配置jdk18>#</a></h2><p>JDK需要在集群3个节点都进行安装，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行</p><p>我们可以在Oracle JDK的官网下载相应版本的JDK，官网地址为:
<a href=https:// target=_blank>http://www.oracle.com/technetwork/java/javase/downloads/index.html</a></p><h3 id=步骤1-创建工作路径>步骤1. 创建工作路径<a hidden class=anchor aria-hidden=true href=#步骤1-创建工作路径>#</a></h3><ol><li>首先需要在终端中输入下列命令，在/usr目录下建立cx工作路径：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>mkdir /usr/cx
</span></span></code></pre></div><ol start=2><li>通过下面的命令实现在节点2和节点3的/usr目录下建立cx工作路径：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;mkdir /usr/cx&#34; 
</span></span><span class=line><span class=cl>ssh realtime-3 &#34;mkdir /usr/cx&#34;
</span></span></code></pre></div><h3 id=步骤2-解压安装包>步骤2. 解压安装包<a hidden class=anchor aria-hidden=true href=#步骤2-解压安装包>#</a></h3><ol><li>我们可以在/usr/software/目录下找到jdk-8u60-linux-x64.tar.gz安装包，通过下列命令将其解压到/usr/cx/目录下：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>tar -zxvf /usr/software/jdk-8u60-linux-x64.tar.gz -C /usr/cx
</span></span></code></pre></div><p>命令执行后的输出内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>(-------------------省略------------------------)
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/jmc.ini
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/jmap
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/serialver
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/wsgen
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/jrunscript
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/javah
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/javac
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/jvisualvm
</span></span><span class=line><span class=cl>jdk1.8.0_60/bin/jcontrol
</span></span><span class=line><span class=cl>jdk1.8.0_60/release
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=2><li>通过下列命令实现在节点2和节点3中将jdk-8u60-linux-x64.tar.gz安装包解压到/usr/cx/目录下：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;tar -zxvf /usr/software/jdk-8u60-linux-x64.tar.gz -C /usr/cx&#34;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>ssh realtime-3 &#34;tar -zxvf /usr/software/jdk-8u60-linux-x64.tar.gz -C /usr/cx&#34;
</span></span></code></pre></div><h3 id=步骤3-配置环境变量>步骤3. 配置环境变量<a hidden class=anchor aria-hidden=true href=#步骤3-配置环境变量>#</a></h3><ol><li>通过下列命令使用vi编辑器打开 ~/.bashrc文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi ~/.bashrc
</span></span></code></pre></div><p>打开的~/.bashrc文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># .bashrc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># User specific aliases and functions
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>alias rm=&#39;rm -i&#39;
</span></span><span class=line><span class=cl>alias cp=&#39;cp -i&#39;
</span></span><span class=line><span class=cl>alias mv=&#39;mv -i&#39;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Source global definitions
</span></span><span class=line><span class=cl>if [ -f /etc/bashrc ]; then
</span></span><span class=line><span class=cl>        . /etc/bashrc
</span></span><span class=line><span class=cl>fi
</span></span><span class=line><span class=cl>(----------------注：需要在此处增加内容-------------------)
</span></span></code></pre></div><ol start=2><li>在文件中写入下列内容：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=k>export</span> <span class=n>JAVA_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>jdk1</span><span class=o>.</span><span class=mf>8.0</span><span class=n>_60</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>bin</span><span class=p>:</span><span class=o>$</span><span class=n>PATH</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>CLASSPATH</span><span class=o>=.</span><span class=p>:</span><span class=o>$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>jre</span><span class=o>/</span><span class=n>lib</span><span class=o>/</span><span class=n>rt</span><span class=o>.</span><span class=n>jar</span><span class=p>:</span><span class=o>$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>jre</span><span class=o>/</span><span class=n>lib</span><span class=o>/</span><span class=n>tools</span><span class=o>.</span><span class=n>jar</span>
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器。</p><ol start=3><li>通过下面的命令将环境变量配置文件分发到节点2和节点3：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp ~/.bashrc root@realtime-2:~/.bashrc  
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp ~/.bashrc root@realtime-3:~/.bashrc
</span></span></code></pre></div><p>命令执行后的输出内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# scp ~/.bashrc root@realtime-2:~/.bashrc
</span></span><span class=line><span class=cl>.bashrc                                      100%  320     0.3KB/s   00:00   
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤4-更新环境变量>步骤4. 更新环境变量<a hidden class=anchor aria-hidden=true href=#步骤4-更新环境变量>#</a></h3><ol><li>执行如下命令，更新环境变量：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>source  ~/.bashrc
</span></span></code></pre></div><ol start=2><li>执行如下命令，更新节点2和节点3的环境变量：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;source  ~/.bashrc&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;source  ~/.bashrc&#34;
</span></span></code></pre></div><h3 id=步骤5-验证jdk是否配置成功>步骤5. 验证JDK是否配置成功<a hidden class=anchor aria-hidden=true href=#步骤5-验证jdk是否配置成功>#</a></h3><ol><li>通过下面的命令验证JDK是否安装并配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>java -version
</span></span></code></pre></div><p>如果出现如下JDK版本信息，则说明安装配置成功：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# java -version
</span></span><span class=line><span class=cl>java version &#34;1.8.0_60&#34;                                              (注：JDK版本号)
</span></span><span class=line><span class=cl>Java(TM) SE Runtime Environment (build 1.8.0_60-b27)              (注：Java运行环境版本号)
</span></span><span class=line><span class=cl>Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=2><li>通过下面的命令验证<code>节点2</code>和<code>节点3</code>的JDK是否安装并配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;java -version&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;java -version&#34;
</span></span></code></pre></div><p>如果没有正确输出相关版本信息，请检查~/.bashrc文件中的JDK环境变量是否配置正确，同时请确定是否使用source ~/.bashrc命令更新环境变量配置</p><h2 id=4-ntp服务配置>4 NTP服务配置<a hidden class=anchor aria-hidden=true href=#4-ntp服务配置>#</a></h2><p>需要在集群的3台节点中都进行NTP服务的配置</p><h3 id=步骤1-ntp服务配置>步骤1. NTP服务配置<a hidden class=anchor aria-hidden=true href=#步骤1-ntp服务配置>#</a></h3><ol><li>在<code>节点1</code>、<code>节点2</code>、<code>节点3</code>中通过下面的命令打开NTP配置文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /etc/ntp.conf
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>（---------------省略----------------）
</span></span><span class=line><span class=cl># Permit all access over the loopback interface.  This could
</span></span><span class=line><span class=cl># be tightened as well, but to do so would effect some of
</span></span><span class=line><span class=cl># the administrative functions.
</span></span><span class=line><span class=cl>restrict 127.0.0.1
</span></span><span class=line><span class=cl>restrict -6 ::1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Hosts on local network are less restricted.
</span></span><span class=line><span class=cl>#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Use public servers from the pool.ntp.org project.
</span></span><span class=line><span class=cl># Please consider joining the pool (http://www.pool.ntp.org/join.html).
</span></span><span class=line><span class=cl>server 0.centos.pool.ntp.org iburst  （注：注释此行内容）
</span></span><span class=line><span class=cl>server 1.centos.pool.ntp.org iburst  （注：注释此行内容）
</span></span><span class=line><span class=cl>server 2.centos.pool.ntp.org iburst  （注：注释此行内容）
</span></span><span class=line><span class=cl>server 3.centos.pool.ntp.org iburst  （注：注释此行内容）
</span></span><span class=line><span class=cl>（注：在此处增加内容）
</span></span><span class=line><span class=cl>#broadcast 192.168.1.255 autokey        # broadcast server
</span></span><span class=line><span class=cl>（---------------省略----------------）
</span></span></code></pre></div><p>在文件中进行下列内容更改（通过server字段设置本机为NTP Serevr服务器，通过restrict限制realtime-2和realtime-3主机名对应的主机可以同步时间）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#server 0.centos.pool.ntp.org iburst
</span></span><span class=line><span class=cl>#server 1.centos.pool.ntp.org iburst
</span></span><span class=line><span class=cl>#server 2.centos.pool.ntp.org iburst
</span></span><span class=line><span class=cl>#server 3.centos.pool.ntp.org iburst
</span></span><span class=line><span class=cl>server 127.127.1.0
</span></span><span class=line><span class=cl>fudge 127.127.1.0 stratum 10
</span></span><span class=line><span class=cl>restrict realtime-2 nomodify notrap
</span></span><span class=line><span class=cl>restrict realtime-3 nomodify notrap
</span></span></code></pre></div><p>更改完成后保存文件并退出编辑器</p><h3 id=步骤2-启动ntp服务>步骤2. 启动NTP服务<a hidden class=anchor aria-hidden=true href=#步骤2-启动ntp服务>#</a></h3><p>为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行。</p><ol><li>通过下面的命令在节点1中设定NTP服务自启动：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>chkconfig ntpd on
</span></span></code></pre></div><ol start=2><li>通过下面的命令在节点1中启动NTP服务：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>service ntpd start
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# service ntpd start
</span></span><span class=line><span class=cl>正在启动 ntpd：                                            [确定]
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=3><li>通过下面的命令在节点2中设定NTP服务自启动：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;chkconfig ntpd on&#34;
</span></span></code></pre></div><ol start=4><li>通过下面的命令在节点2中启动NTP服务：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;service ntpd start&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-2 &#34;service ntpd start&#34;
</span></span><span class=line><span class=cl>正在启动 ntpd：[确定]
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=5><li>通过下面的命令在节点3中设定NTP服务自启动：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;chkconfig ntpd on&#34;
</span></span></code></pre></div><ol start=6><li>通过下面的命令在节点3中启动NTP服务：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;service ntpd start&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-3 &#34;service ntpd start&#34;
</span></span><span class=line><span class=cl>正在启动 ntpd：[确定]
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p><em>如果服务无法正常启动，会出现相关的错误提示信息，只需要根据错误提示进行更改即可。</em></p><h3 id=步骤3-ntp服务状态查看>步骤3. NTP服务状态查看<a hidden class=anchor aria-hidden=true href=#步骤3-ntp服务状态查看>#</a></h3><p>为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行。</p><ol><li>通过下面的命令查看节点1中NTP服务的运行状态：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ntpstat
</span></span></code></pre></div><p>命令运行后的返回结果如下所示（由于节点1是作为Server节点，所以其状态会很快变成synchronised，此时说明服务已经正常启动）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ntpstat
</span></span><span class=line><span class=cl>synchronised to local net at stratum 11
</span></span><span class=line><span class=cl>   time correct to within 449 ms
</span></span><span class=line><span class=cl>   polling server every 64 s
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=2><li>通过下面的命令查看<code>节点2</code>和<code>节点三</code>中NTP服务的运行状态：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;ntpstat&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;ntpstat&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示（由于节点2需要同步节点1的时间，因此需要大概15分钟其状态才会由unsynchronised会变成synchronised，当状态变为synchronised时说明服务已经正常启动）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-2 &#34;ntpstat&#34;
</span></span><span class=line><span class=cl>unsynchronised
</span></span><span class=line><span class=cl>   polling server every 64 s
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>服务正常启动后的状态如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-3 &#34;ntpstat&#34;
</span></span><span class=line><span class=cl>synchronised to NTP server (10.1.1.4) at stratum 12
</span></span><span class=line><span class=cl>   time correct to within 25 ms
</span></span><span class=line><span class=cl>   polling server every 64 s
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p><em>当3个节点的状态都显示为synchronised时，则表示ntp服务已经启动成功；如果一直显示unsynchronised,可能是配置文件有错误，因此需要检查IP地址是否配置正确。</em></p><p>同学们不必一直等待，可以先进行下文的实验，然后过后再查看NTP服务状态。</p><h2 id=5-selinux安全配置>5 SElinux安全配置<a hidden class=anchor aria-hidden=true href=#5-selinux安全配置>#</a></h2><p>需要在集群3个节点都进行SElinux配置，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行。</p><ol><li>通过下面的命令，关闭<code>节点1</code>、<code>节点2</code>、<code>节点3</code>的SElinux安全设置：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>/bin/sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/&#39; /etc/selinux/config
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;/bin/sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/&#39; /etc/selinux/config&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;/bin/sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/&#39; /etc/selinux/config&#34;
</span></span></code></pre></div><h2 id=6-安装配置zookeeper集群>6 安装配置ZooKeeper集群<a hidden class=anchor aria-hidden=true href=#6-安装配置zookeeper集群>#</a></h2><p>由于我们需要搭建一套具备高可用性的Hadoop集群，因此需要通过ZooKeeper来进行集群中服务的协调。ZooKeeper需要在集群3个节点进行安装配置，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行</p><p>在模板中我们已经将ZooKeeper安装文件zookeeper-3.4.6.tar.gz放到了/usr/software目录下，同学们可以直接使用</p><h3 id=步骤1-解压安装包>步骤1. 解压安装包<a hidden class=anchor aria-hidden=true href=#步骤1-解压安装包>#</a></h3><ol><li>通过下列命令将ZooKeeper安装包解压到/usr/cx目录下：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>tar -zxvf /usr/software/zookeeper-3.4.6.tar.gz -C /usr/cx
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>(---------------------省略--------------------)
</span></span><span class=line><span class=cl>zookeeper-3.4.6/recipes/queue/test/org/apache/zookeeper/recipes/queue/DistributedQueueTest.java
</span></span><span class=line><span class=cl>zookeeper-3.4.6/recipes/queue/build.xml
</span></span><span class=line><span class=cl>zookeeper-3.4.6/zookeeper-3.4.6.jar
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/cobertura/
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/cobertura/README.txt
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/jline-0.9.94.jar
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/log4j-1.2.16.LICENSE.txt
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/slf4j-log4j12-1.6.1.jar
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/jdiff/
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/jdiff/zookeeper_3.1.1.xml
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/jdiff/zookeeper_3.4.6-SNAPSHOT.xml
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/jdiff/zookeeper_3.4.6.xml
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/slf4j-api-1.6.1.jar
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/log4j-1.2.16.jar
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/netty-3.7.0.Final.jar
</span></span><span class=line><span class=cl>zookeeper-3.4.6/lib/jline-0.9.94.LICENSE.txt
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=2><li>解压完成后，我们可以查看解压后的文件夹内容：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ls /usr/cx/zookeeper-3.4.6/
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ls /usr/cx/zookeeper-3.4.6/
</span></span><span class=line><span class=cl>bin          dist-maven       LICENSE.txt           src
</span></span><span class=line><span class=cl>build.xml    docs             NOTICE.txt            zookeeper-3.4.6.jar
</span></span><span class=line><span class=cl>CHANGES.txt  ivysettings.xml  README_packaging.txt  zookeeper-3.4.6.jar.asc
</span></span><span class=line><span class=cl>conf         ivy.xml          README.txt            zookeeper-3.4.6.jar.md5
</span></span><span class=line><span class=cl>contrib      lib              recipes               zookeeper-3.4.6.jar.sha1
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤2-数据存储目录创建>步骤2. 数据存储目录创建<a hidden class=anchor aria-hidden=true href=#步骤2-数据存储目录创建>#</a></h3><ol><li>通过下面的命令创建ZooKeeper数据存储目录：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>mkdir -p /home/data
</span></span></code></pre></div><p>通过下面的命令创建ZooKeeper日志存储目录：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>mkdir -p /home/logs
</span></span></code></pre></div><ol start=2><li>通过下面的命令在<code>节点2</code>、<code>节点3</code>中创建ZooKeeper数据存储目录：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;mkdir -p /home/data&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;mkdir -p /home/data&#34;
</span></span></code></pre></div><p>通过下面的命令在<code>节点2</code>、<code>节点3</code>中创建ZooKeeper日志存储目录：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;mkdir -p /home/logs&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;mkdir -p /home/logs&#34;
</span></span></code></pre></div><h3 id=步骤3-主机myid编号文件创建>步骤3. 主机myid编号文件创建<a hidden class=anchor aria-hidden=true href=#步骤3-主机myid编号文件创建>#</a></h3><ol><li>通过下面的命令创建myid文件，并设置节点1对应的编号为1（集群启动后会通过此编号来进行主机识别）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>echo &#34;1&#34; &gt; /home/data/myid
</span></span></code></pre></div><ol start=2><li>通过下面的命令在节点2中创建myid文件，并设置节点2对应的编号为2（集群启动后会通过此编号来进行主机识别）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;echo &#34;2&#34; &gt; /home/data/myid&#34;
</span></span></code></pre></div><ol start=3><li>通过下面的命令在节点3中创建myid文件，并设置节点3对应的编号为3（集群启动后会通过此编号来进行主机识别）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;echo &#34;3&#34; &gt; /home/data/myid&#34;
</span></span></code></pre></div><h3 id=步骤4-zookeeper配置文件编辑>步骤4. ZooKeeper配置文件编辑<a hidden class=anchor aria-hidden=true href=#步骤4-zookeeper配置文件编辑>#</a></h3><ol><li>通过下列命令创建并打开zoo.cfg配置文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/zookeeper-3.4.6/conf/zoo.cfg
</span></span></code></pre></div><p>在文件中写入下列内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>tickTime=2000
</span></span><span class=line><span class=cl>dataDir=/home/data
</span></span><span class=line><span class=cl>clientPort=2181
</span></span><span class=line><span class=cl>dataLogDir=/home/logs
</span></span><span class=line><span class=cl>initLimit=5
</span></span><span class=line><span class=cl>syncLimit=2
</span></span><span class=line><span class=cl>server.1=realtime-1:2888:3888
</span></span><span class=line><span class=cl>server.2=realtime-2:2888:3888
</span></span><span class=line><span class=cl>server.3=realtime-3:2888:3888
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器。</p><p>在上述配置中，我们设置心跳时间为2000毫秒，设置ZooKeeper在本地保存数据的目录为/home/data，ZooKeeper监听客户端连接的端口为2181,设置所有Follower和Leader进行同步的时间为5s，设置一个Follower和Leader进行同步的时间为2s。同时设定集群中有3台主机，其中realtime-1对应的主机编号为1，Follower与Leader之间交换信息的端口为2888，进行Leader选举的端口为3888；realtime-2对应的主机编号为2，Follower与Leader之间交换信息的端口为2888，进行Leader选举的端口为3888；realtime-3对应的主机编号为3，Follower与Leader之间交换信息的端口为2888，进行Leader选举的端口为3888。</p><h3 id=步骤5-文件分发>步骤5. 文件分发<a hidden class=anchor aria-hidden=true href=#步骤5-文件分发>#</a></h3><ol><li>通过下面的命令将节点1的ZooKeeper文件包分发到<code>节点2</code>、<code>节点3</code>中：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp -r /usr/cx/zookeeper-3.4.6 root@realtime-2:/usr/cx/
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp -r /usr/cx/zookeeper-3.4.6 root@realtime-3:/usr/cx/
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>（----------------------省略------------------------）
</span></span><span class=line><span class=cl>Makefile.am                                   100%   74     0.1KB/s   00:00   
</span></span><span class=line><span class=cl>zkServer.cmd                                  100% 1084     1.1KB/s   00:00   
</span></span><span class=line><span class=cl>zkEnv.sh                                      100% 2696     2.6KB/s   00:00   
</span></span><span class=line><span class=cl>zkCleanup.sh                                  100% 1937     1.9KB/s   00:00   
</span></span><span class=line><span class=cl>zkCli.sh                                      100% 1534     1.5KB/s   00:00   
</span></span><span class=line><span class=cl>zkEnv.cmd                                     100% 1333     1.3KB/s   00:00   
</span></span><span class=line><span class=cl>zkCli.cmd                                     100% 1049     1.0KB/s   00:00   
</span></span><span class=line><span class=cl>README.txt                                    100%  238     0.2KB/s   00:00   
</span></span><span class=line><span class=cl>zkServer.sh                                   100% 5742     5.6KB/s   00:00   
</span></span><span class=line><span class=cl>NOTICE.txt                                    100%  170     0.2KB/s   00:00   
</span></span><span class=line><span class=cl>zookeeper-3.4.6.jar.md5                       100%   33     0.0KB/s   00:00   
</span></span><span class=line><span class=cl>README.txt                                    100% 1585     1.6KB/s   00:00   
</span></span><span class=line><span class=cl>CHANGES.txt                                   100%   79KB  78.9KB/s   00:00   
</span></span><span class=line><span class=cl>zookeeper-3.4.6.jar.sha1                      100%   41     0.0KB/s   00:00   
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤6-zookeeper环境变量配置>步骤6. ZooKeeper环境变量配置<a hidden class=anchor aria-hidden=true href=#步骤6-zookeeper环境变量配置>#</a></h3><ol><li>通过下列命令使用vi编辑器打开 ~/.bashrc文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi ~/.bashrc
</span></span></code></pre></div><p>打开的~/.bashrc文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=c1># .bashrc</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># User specific aliases and functions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>alias</span> <span class=n>rm</span><span class=o>=</span><span class=s1>&#39;rm -i&#39;</span>
</span></span><span class=line><span class=cl><span class=n>alias</span> <span class=n>cp</span><span class=o>=</span><span class=s1>&#39;cp -i&#39;</span>
</span></span><span class=line><span class=cl><span class=n>alias</span> <span class=n>mv</span><span class=o>=</span><span class=s1>&#39;mv -i&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Source global definitions</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=p>[</span> <span class=o>-</span><span class=n>f</span> <span class=o>/</span><span class=n>etc</span><span class=o>/</span><span class=n>bashrc</span> <span class=p>];</span> <span class=n>then</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span> <span class=o>/</span><span class=n>etc</span><span class=o>/</span><span class=n>bashrc</span>
</span></span><span class=line><span class=cl><span class=n>fi</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>JAVA_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>jdk1</span><span class=o>.</span><span class=mf>8.0</span><span class=n>_60</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>bin</span><span class=p>:</span><span class=o>$</span><span class=n>PATH</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>CLASSPATH</span><span class=o>=.</span><span class=p>:</span><span class=o>$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>jre</span><span class=o>/</span><span class=n>lib</span><span class=o>/</span><span class=n>rt</span><span class=o>.</span><span class=n>jar</span><span class=p>:</span><span class=o>$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>jre</span><span class=o>/</span><span class=n>lib</span><span class=o>/</span><span class=n>tools</span><span class=o>.</span><span class=n>jar</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=o>----------------</span><span class=err>注：需要在此处增加内容</span><span class=o>-------------------</span><span class=p>)</span>
</span></span></code></pre></div><ol start=2><li>在文件中写入下列内容：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=k>export</span> <span class=n>ZK_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>zookeeper</span><span class=o>-</span><span class=mf>3.4</span><span class=o>.</span><span class=mi>6</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>PATH</span><span class=p>:</span><span class=o>$</span><span class=n>ZK_HOME</span><span class=o>/</span><span class=n>bin</span>
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器。</p><ol start=3><li>通过下面的命令将环境变量配置文件分发到<code>节点2</code>和<code>节点3</code>：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp ~/.bashrc root@realtime-2:~/.bashrc
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp ~/.bashrc root@realtime-3:~/.bashrc
</span></span></code></pre></div><h3 id=步骤7-更新环境变量>步骤7. 更新环境变量<a hidden class=anchor aria-hidden=true href=#步骤7-更新环境变量>#</a></h3><ol><li>执行如下命令，更新环境变量：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>source  ~/.bashrc
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;source  ~/.bashrc&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;source  ~/.bashrc&#34;
</span></span></code></pre></div><h3 id=步骤8-验证环境变量是否配置成功>步骤8. 验证环境变量是否配置成功<a hidden class=anchor aria-hidden=true href=#步骤8-验证环境变量是否配置成功>#</a></h3><ol><li>通过下面的命令验证环境变量是否配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>zkServer.sh
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;zkServer.sh&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;zkServer.sh&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# zkServer.sh
</span></span><span class=line><span class=cl>JMX enabled by default
</span></span><span class=line><span class=cl>Using config: /usr/cx/zookeeper-3.4.6/bin/../conf/zoo.cfg
</span></span><span class=line><span class=cl>Usage: /usr/cx/zookeeper-3.4.6/bin/zkServer.sh {start|start-foreground|stop|restart|status|upgrade|print-cmd}
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>由输出内容可以看出，ZooKeeper环境变量已经配置正确，并且可以正常执行。</p><h2 id=7-zookeeper启动及状态查看>7 ZooKeeper启动及状态查看<a hidden class=anchor aria-hidden=true href=#7-zookeeper启动及状态查看>#</a></h2><h3 id=步骤1-zookeeper启动>步骤1. ZooKeeper启动<a hidden class=anchor aria-hidden=true href=#步骤1-zookeeper启动>#</a></h3><ol><li>通过下面的命令启动ZooKeeper服务：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>zkServer.sh start
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;zkServer.sh start&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;zkServer.sh start&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# zkServer.sh start
</span></span><span class=line><span class=cl>JMX enabled by default
</span></span><span class=line><span class=cl>Using config: /usr/cx/zookeeper-3.4.6/bin/../conf/zoo.cfg
</span></span><span class=line><span class=cl>Starting zookeeper ... STARTED
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤2-zookeeper运行状态查看>步骤2. ZooKeeper运行状态查看<a hidden class=anchor aria-hidden=true href=#步骤2-zookeeper运行状态查看>#</a></h3><p>ZooKeeper运行之后会随机进行follower角色以及leader角色选举，当leader角色节点出现异常后，会从其他节点中选举出新的leader角色。至于具体哪个节点处于leader状态，需要根据实际情况确定，并不是千篇一律的</p><p>通过下面的命令可以查看ZooKeeper运行状态：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>zkServer.sh status
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;zkServer.sh status&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;zkServer.sh status&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示（由返回结果的Mode字段可以看出，当前节点是作为follower角色运行的）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# zkServer.sh status
</span></span><span class=line><span class=cl>JMX enabled by default
</span></span><span class=line><span class=cl>Using config: /usr/cx/zookeeper-3.4.6/bin/../conf/zoo.cfg
</span></span><span class=line><span class=cl>Mode: follower
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h2 id=8-安装配置hadoop集群>8 安装配置Hadoop集群<a hidden class=anchor aria-hidden=true href=#8-安装配置hadoop集群>#</a></h2><p>Hadoop需要在集群3个节点进行安装配置，为了操作方便，我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行</p><blockquote><p>在模板中，我们已经将相应的Hadoop安装包hadoop-2.7.1.tar.gz放到/usr/software/目录下，同学们不需要再次下载，可以直接使用。</p></blockquote><h3 id=步骤1-数据存储目录创建>步骤1. 数据存储目录创建<a hidden class=anchor aria-hidden=true href=#步骤1-数据存储目录创建>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=o>/</span><span class=n>hdfs</span><span class=o>/</span><span class=n>namenode</span>
</span></span><span class=line><span class=cl><span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=o>/</span><span class=n>hdfs</span><span class=o>/</span><span class=n>datanode</span>
</span></span><span class=line><span class=cl><span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=o>/</span><span class=n>hdfs</span><span class=o>/</span><span class=n>journalnode</span>
</span></span><span class=line><span class=cl><span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=o>/</span><span class=k>var</span><span class=o>/</span><span class=nb>log</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>yarn</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=s2>&#34;mkdir -p /hdfs/namenode&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=s2>&#34;mkdir -p /hdfs/datanode&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=s2>&#34;mkdir -p /hdfs/journalnode&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=s2>&#34;mkdir -p /var/log/hadoop-yarn&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>3</span> <span class=s2>&#34;mkdir -p /hdfs/namenode&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>3</span> <span class=s2>&#34;mkdir -p /hdfs/datanode&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>3</span> <span class=s2>&#34;mkdir -p /hdfs/journalnode&#34;</span>
</span></span><span class=line><span class=cl><span class=n>ssh</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>3</span> <span class=s2>&#34;mkdir -p /var/log/hadoop-yarn&#34;</span>
</span></span></code></pre></div><h3 id=步骤2-解压安装文件>步骤2. 解压安装文件<a hidden class=anchor aria-hidden=true href=#步骤2-解压安装文件>#</a></h3><p>通过下列命令解压Hadoop安装文件，将文件解压到/usr/cx目录下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>tar -zxvf /usr/software/hadoop-2.7.1.tar.gz -C /usr/cx
</span></span></code></pre></div><p>命令执行后的输出内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>(-------------------省略------------------------)
</span></span><span class=line><span class=cl>hadoop-2.7.1/libexec/hdfs-config.sh
</span></span><span class=line><span class=cl>hadoop-2.7.1/README.txt
</span></span><span class=line><span class=cl>hadoop-2.7.1/NOTICE.txt
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhadoop.a
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhadoop.so
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhadooppipes.a
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhdfs.so.0.0.0
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhadooputils.a
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhdfs.a
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhdfs.so
</span></span><span class=line><span class=cl>hadoop-2.7.1/lib/native/libhadoop.so.1.0.0
</span></span><span class=line><span class=cl>hadoop-2.7.1/LICENSE.txt
</span></span><span class=line><span class=cl>[root@master ~]#
</span></span></code></pre></div><h3 id=步骤3-编辑hadoop配置文件>步骤3. 编辑Hadoop配置文件：<a hidden class=anchor aria-hidden=true href=#步骤3-编辑hadoop配置文件>#</a></h3><ol><li>使用vi命令打开hadoop-env.sh配置文件进行编辑：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/hadoop-2.7.1/etc/hadoop/hadoop-env.sh
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>(</span><span class=o>-------------------</span><span class=err>省略</span><span class=o>------------------------</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Set Hadoop-specific environment variables here.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># The only required environment variable is JAVA_HOME.  All others are</span>
</span></span><span class=line><span class=cl><span class=c1># optional.  When running a distributed configuration it is best to</span>
</span></span><span class=line><span class=cl><span class=c1># set JAVA_HOME in this file, so that it is correctly defined on</span>
</span></span><span class=line><span class=cl><span class=c1># remote nodes.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># The java implementation to use.</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>JAVA_HOME</span><span class=o>=$</span><span class=p>{</span><span class=n>JAVA_HOME</span><span class=p>}</span>             <span class=p>(</span><span class=err>注：需要对此行内容进行更改，为</span><span class=n>Hadoop绑定Java运行环境</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># The jsvc implementation to use. Jsvc is required to run secure datanodes</span>
</span></span><span class=line><span class=cl><span class=c1># that bind to privileged ports to provide authentication of data transfer</span>
</span></span><span class=line><span class=cl><span class=c1># protocol.  Jsvc is not required if SASL is configured for authentication of</span>
</span></span><span class=line><span class=cl><span class=c1># data transfer protocol using non-privileged ports.</span>
</span></span><span class=line><span class=cl><span class=c1>#export JSVC_HOME=${JSVC_HOME}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>HADOOP_CONF_DIR</span><span class=o>=$</span><span class=p>{</span><span class=n>HADOOP_CONF_DIR</span><span class=p>:</span><span class=o>-</span><span class=s2>&#34;/etc/hadoop&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=o>-------------------</span><span class=err>省略</span><span class=o>------------------------</span><span class=p>)</span>
</span></span></code></pre></div><p>在文件中进行下列内容更改，将JAVA_HOME对应的值改成实际的JDK安装路径：</p><p>export JAVA_HOME=/usr/cx/jdk1.8.0_60</p><p>编辑完成后保存文件并退出vi编辑器。</p><ol start=2><li>使用vi命令打开hdfs-site.xml文件进行配置：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/hadoop-2.7.1/etc/hadoop/hdfs-site.xml
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;!--
</span></span><span class=line><span class=cl>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span class=line><span class=cl>  you may not use this file except in compliance with the License.
</span></span><span class=line><span class=cl>  You may obtain a copy of the License at
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  Unless required by applicable law or agreed to in writing, software
</span></span><span class=line><span class=cl>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span class=line><span class=cl>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span class=line><span class=cl>  See the License for the specific language governing permissions and
</span></span><span class=line><span class=cl>  limitations under the License. See accompanying LICENSE file.
</span></span><span class=line><span class=cl>--&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;configuration&gt;
</span></span><span class=line><span class=cl>(注：需要在此处进行相关内容配置)
</span></span><span class=line><span class=cl>&lt;/configuration&gt;
</span></span></code></pre></div><p>在文件中<code>&lt;configuration></code>和<code>&lt;/configuration></code>之间增加下列内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>/*配置DataNode的数据存储目录，需要与上文创建的目录相对应*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;/hdfs/datanode&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*配置数据块大小为256M*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.blocksize&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;268435456&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*自定义的HDFS服务名，在高可用集群中，无法配置单一HDFS服务器入口，所以需要指定一个逻辑上的服务名，当访问服务名时，会自动选择NameNode节点进行访问*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.nameservices&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;HDFScluster&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*配置NameNode的数据存储目录，需要与上文创建的目录相对应*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;/hdfs/namenode&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*定义HDFS服务名所指向的NameNode主机名称*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.ha.namenodes.HDFScluster&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;realtime-1,realtime-2&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置NameNode的完整监听地址*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.namenode.rpc-address.HDFScluster.realtime-1&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;realtime-1:8020&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置NameNode的完整监听地址*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.namenode.rpc-address.HDFScluster.realtime-2&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;realtime-2:8020&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置NameNode的HTTP访问地址*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.namenode.http-address.HDFScluster.realtime-1&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;realtime-1:50070&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置NameNode的HTTP访问地址*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.namenode.http-address.HDFScluster.realtime-2&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;realtime-2:50070&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置主从NameNode元数据同步地址，官方推荐将nameservice作为最后的journal ID*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;qjournal://realtime-1:8485;realtime-2:8485;realtime-3:8485/HDFScluster&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置HDFS客户端用来连接集群中活动状态NameNode节点的Java类*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.client.failover.proxy.provider.HDFScluster&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置SSH登录的私钥文件地址*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*启动fence过程，确保集群高可用性*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;shell(/bin/true)&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*配置JournalNode的数据存储目录，需要与上文创建的目录相对应*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;/hdfs/journalnode&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置自动切换活跃节点，保证集群高可用性*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;true&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*配置数据块副本数*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.replication&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;3&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*将dfs.webhdfs.enabled属性设置为true，否则就不能使用webhdfs的LISTSTATUS、LIST FILESTATUS等需要列出文件、文件夹状态的命令，因为这些信息都是由namenode保存的*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;true&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><p><em>在集群中，对HDFS集群访问的入口是NameNode所在的服务器。但是在两个NameNode节点的HA集群中，无法配置单一服务器入口，所以需要通过dfs.nameservices指定一个逻辑上的服务名，这个服务名是自定义的。当外界访问HDFS集群时，入口就变为这个服务名称，Hadoop会自动实现将访问请求转发到实际的处于Active状态的NameNode节点上。</em></p><p><em>当配置了HDFS HA集群时，会有两个NameNode，为了避免两个NameNode都为Active状态，当发生failover时，Standby的节点要执行一系列方法把原来那个Active节点中不健康的NameNode服务给杀掉（这个过程就称为fence）。而dfs.ha.fencing.methods配置就是配置了执行杀死原来Active NameNode服务的方法，为了保险起见，因此指定无论如何都把StandBy节点的状态提升为Active，所以最后要配置一个shell(/bin/true)，保证不论前面的方法执行的情况如何，最后fence过程返回的结果都为True。fence操作需要通过SSH进行节点间的访问，因此需要配置dfs.ha.fencing.ssh.private-key-files为所需要用到的私钥文件路径信息。</em></p><ol start=3><li>使用vi命令打开core-site.xml配置文件进行编辑：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/hadoop-2.7.1/etc/hadoop/core-site.xml
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;!--
</span></span><span class=line><span class=cl>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span class=line><span class=cl>  you may not use this file except in compliance with the License.
</span></span><span class=line><span class=cl>  You may obtain a copy of the License at
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  Unless required by applicable law or agreed to in writing, software
</span></span><span class=line><span class=cl>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span class=line><span class=cl>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span class=line><span class=cl>  See the License for the specific language governing permissions and
</span></span><span class=line><span class=cl>  limitations under the License. See accompanying LICENSE file.
</span></span><span class=line><span class=cl>--&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;configuration&gt;
</span></span><span class=line><span class=cl>(注：需要在此处进行相关内容配置)
</span></span><span class=line><span class=cl>&lt;/configuration&gt;
</span></span></code></pre></div><p>在文件中和之间增加下列内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>/*设置默认的HDFS访问路径，需要与hdfs-site.xml中的HDFS服务名相一致*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;hdfs://HDFScluster&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*临时文件夹路径设置*/
</span></span><span class=line><span class=cl>&lt;property&gt; 
</span></span><span class=line><span class=cl>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt; 
</span></span><span class=line><span class=cl>&lt;value&gt;/usr/tmp&lt;/value&gt; 
</span></span><span class=line><span class=cl>&lt;/property&gt; 
</span></span><span class=line><span class=cl>/*配置ZooKeeper服务集群，用于活跃NameNode节点的选举*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;realtime-1:2181,realtime-2:2181,realtime-3:2181&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置数据压缩算法*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;io.compression.codecs&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.SnappyCodec&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置使用hduser用户可以代理所有主机用户进行任务提交*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;hadoop.proxyuser.hduser.host&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;*&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span><span class=line><span class=cl>/*设置使用hduser用户可以代理所有组用户进行任务提交*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;hadoop.proxyuser.hduser.groups&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;*&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><p><em>对HDFS集群访问的入口是NameNode所在的服务器，但是在两个NameNode节点的HA集群中，无法配置单一服务器入口，所以需要在hdfs-site.xml中通过dfs.nameservices指定一个逻辑上的服务名，因此此处的fs.defaultFS配置的入口地址需要与hdfs-site.xml中dfs.nameservices所配置的一致。</em></p><ol start=4><li>使用vi命令打开yarn-site.xml文件进行配置：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/hadoop-2.7.1/etc/hadoop/yarn-site.xml
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&lt;?xml version=&#34;1.0&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;!--
</span></span><span class=line><span class=cl>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span class=line><span class=cl>  you may not use this file except in compliance with the License.
</span></span><span class=line><span class=cl>  You may obtain a copy of the License at
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  Unless required by applicable law or agreed to in writing, software
</span></span><span class=line><span class=cl>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span class=line><span class=cl>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span class=line><span class=cl>  See the License for the specific language governing permissions and
</span></span><span class=line><span class=cl>  limitations under the License. See accompanying LICENSE file.
</span></span><span class=line><span class=cl>--&gt;
</span></span><span class=line><span class=cl>&lt;configuration&gt;
</span></span><span class=line><span class=cl>(注：需要在此处进行相关内容配置)
</span></span><span class=line><span class=cl>&lt;!-- Site specific YARN configuration properties --&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;/configuration&gt;
</span></span></code></pre></div><p>在文件中和之间增加下列内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=o>/*</span><span class=err>设置</span><span class=n>NodeManager上运行的附属服务</span><span class=err>，需配置成</span><span class=n>mapreduce_shuffle才可运行MapReduce程序</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>aux</span><span class=o>-</span><span class=n>services</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>mapreduce_shuffle</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>aux</span><span class=o>-</span><span class=n>services</span><span class=o>.</span><span class=n>mapreduce_shuffle</span><span class=o>.</span><span class=k>class</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>mapred</span><span class=o>.</span><span class=n>ShuffleHandler</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设置任务日志存储目录</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>log</span><span class=o>-</span><span class=n>dirs</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>file</span><span class=p>:</span><span class=o>///</span><span class=k>var</span><span class=o>/</span><span class=nb>log</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>yarn</span> <span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设置</span><span class=n>Hadoop依赖包地址</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>application</span><span class=o>.</span><span class=n>classpath</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>common</span><span class=o>/*</span><span class=p>,</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>common</span><span class=o>/</span><span class=n>lib</span><span class=o>/*</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>hdfs</span><span class=o>/*</span><span class=p>,</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>hdfs</span><span class=o>/</span><span class=n>lib</span><span class=o>/*</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>mapreduce</span><span class=o>/*</span><span class=p>,</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>mapreduce</span><span class=o>/</span><span class=n>lib</span><span class=o>/*</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>yarn</span><span class=o>/*</span><span class=p>,</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>share</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>yarn</span><span class=o>/</span><span class=n>lib</span><span class=o>/*</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>开启</span><span class=n>resourcemanager</span> <span class=err>的高可用性功能</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>ha</span><span class=o>.</span><span class=n>enabled</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=bp>true</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>标识集群中的</span><span class=n>resourcemanager</span><span class=err>，如果设置该选项，需要确保所有的</span><span class=n>resourcemanager节点在配置中都有自己的逻辑id</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>cluster</span><span class=o>-</span><span class=n>id</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>YARNcluster</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设置</span><span class=n>resourcemanager节点的逻辑id</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>ha</span><span class=o>.</span><span class=n>rm</span><span class=o>-</span><span class=n>ids</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>rm1</span><span class=p>,</span><span class=n>rm2</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>为每个逻辑</span><span class=n>id绑定实际的主机名称</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>hostname</span><span class=o>.</span><span class=n>rm1</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>hostname</span><span class=o>.</span><span class=n>rm2</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>指定</span><span class=n>ZooKeeper服务地址</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>zk</span><span class=o>-</span><span class=n>address</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span><span class=mi>2181</span><span class=p>,</span><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span><span class=mi>2181</span><span class=p>,</span><span class=n>realtime</span><span class=o>-</span><span class=mi>3</span><span class=p>:</span><span class=mi>2181</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>指定</span><span class=n>resourcemanager的WEB访问地址</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>webapp</span><span class=o>.</span><span class=n>address</span><span class=o>.</span><span class=n>rm1</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span><span class=mi>8089</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>webapp</span><span class=o>.</span><span class=n>address</span><span class=o>.</span><span class=n>rm2</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span><span class=mi>8089</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设定虚拟内存与实际内存的比例，比例值越高，则可用虚拟内存就越多</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>vmem</span><span class=o>-</span><span class=n>pmem</span><span class=o>-</span><span class=n>ratio</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=mi>3</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设定单个容器可以申领到的最小内存资源</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=n>minimum</span><span class=o>-</span><span class=n>allocation</span><span class=o>-</span><span class=n>mb</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=mi>32</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设置当任务运行结束后，日志文件被转移到的</span><span class=n>HDFS目录</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>remote</span><span class=o>-</span><span class=n>app</span><span class=o>-</span><span class=nb>log</span><span class=o>-</span><span class=n>dir</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>hdfs</span><span class=p>:</span><span class=o>//</span><span class=n>HDFScluster</span><span class=o>/</span><span class=k>var</span><span class=o>/</span><span class=nb>log</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>yarn</span><span class=o>/</span><span class=n>apps</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设定资源调度策略，目前可用的有</span><span class=n>FIFO</span><span class=err>、</span><span class=n>Capacity</span> <span class=n>Scheduler和Fair</span> <span class=n>Scheduler</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=k>class</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>yarn</span><span class=o>.</span><span class=n>server</span><span class=o>.</span><span class=n>resourcemanager</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=n>capacity</span><span class=o>.</span><span class=n>CapacityScheduler</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设定每个任务能够申领到的最大虚拟</span><span class=n>CPU数目</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=n>maximum</span><span class=o>-</span><span class=n>allocation</span><span class=o>-</span><span class=n>vcores</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span> 
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=mi>8</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设置任务完成指定时间（秒）之后，删除任务的本地化文件和日志目录</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>delete</span><span class=o>.</span><span class=n>debug</span><span class=o>-</span><span class=n>delay</span><span class=o>-</span><span class=n>sec</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=mi>600</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设置志在</span><span class=n>HDFS上保存多长时间</span><span class=err>（秒）</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>log</span><span class=o>.</span><span class=n>retain</span><span class=o>-</span><span class=n>seconds</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=mi>86400</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>/*</span><span class=err>设定物理节点有</span><span class=mi>2</span><span class=n>G内存加入资源池</span><span class=o>*/</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>property</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>name</span><span class=o>&gt;</span><span class=n>yarn</span><span class=o>.</span><span class=n>nodemanager</span><span class=o>.</span><span class=n>resource</span><span class=o>.</span><span class=n>memory</span><span class=o>-</span><span class=n>mb</span><span class=o>&lt;/</span><span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>value</span><span class=o>&gt;</span><span class=mi>2048</span><span class=o>&lt;/</span><span class=n>value</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=o>&lt;/</span><span class=n>property</span><span class=o>&gt;</span>
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><p><em>在集群中，提交任务的入口是ResourceManager所在的服务器。但是在两个ResourceManager节点的HA集群中，无法配置单一服务器入口，所以需要通过yarn.resourcemanager.cluster-id指定一个逻辑上的服务名，这个服务名是自定义的。当外界向集群提交任务时，入口就变为这个服务名称，YARN会自动实现将访问请求转发到实际的处于Active状态的ResourceManager节点上。由于配置了逻辑服务名，所以需要设置resourcemanager节点的逻辑id，并为每个逻辑id绑定实际的主机名称</em></p><ol start=5><li>使用下列命令复制mapred-site.xml.template文件并重命名为mapred-site.xml：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cp /usr/cx/hadoop-2.7.1/etc/hadoop/mapred-site.xml.template /usr/cx/hadoop-2.7.1/etc/hadoop/mapred-site.xml
</span></span></code></pre></div><ol start=6><li>使用vi命令打开mapred-site.xml文件进行配置：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/hadoop-2.7.1/etc/hadoop/mapred-site.xml
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&lt;?xml version=&#34;1.0&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
</span></span><span class=line><span class=cl>&lt;!--
</span></span><span class=line><span class=cl>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span class=line><span class=cl>  you may not use this file except in compliance with the License.
</span></span><span class=line><span class=cl>  You may obtain a copy of the License at
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  Unless required by applicable law or agreed to in writing, software
</span></span><span class=line><span class=cl>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span class=line><span class=cl>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span class=line><span class=cl>  See the License for the specific language governing permissions and
</span></span><span class=line><span class=cl>  limitations under the License. See accompanying LICENSE file.
</span></span><span class=line><span class=cl>--&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;configuration&gt;
</span></span><span class=line><span class=cl>(注：需要在此处进行相关内容配置)
</span></span><span class=line><span class=cl>&lt;/configuration&gt;
</span></span></code></pre></div><p>在文件中和之间增加下列内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>/*Hadoop对MapReduce运行框架一共提供了3种实现，在mapred-site.xml中通过&#34;mapreduce.framework.name&#34;这个属性来设置为&#34;classic&#34;、&#34;yarn&#34;或者&#34;local&#34;*/
</span></span><span class=line><span class=cl>&lt;property&gt;
</span></span><span class=line><span class=cl>&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
</span></span><span class=line><span class=cl>&lt;value&gt;yarn&lt;/value&gt;
</span></span><span class=line><span class=cl>&lt;/property&gt;
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><ol start=7><li>使用vi命令打开slaves文件进行配置（要与我们前文设置的主机名相互一致，否则将会引起Hadoop相关进程无法正确启动）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi /usr/cx/hadoop-2.7.1/etc/hadoop/slaves
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>localhost        （注：需要对此内容进行更改，配置为Slave节点的实际主机名）
</span></span></code></pre></div><p>将文件中的内容更改为下列内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>realtime-1
</span></span><span class=line><span class=cl>realtime-2
</span></span><span class=line><span class=cl>realtime-3
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><h3 id=步骤4-文件分发>步骤4. 文件分发<a hidden class=anchor aria-hidden=true href=#步骤4-文件分发>#</a></h3><ol><li>通过下面的命令将节点1的Hadoop文件包分发到节点2中：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp -r /usr/cx/hadoop-2.7.1 root@realtime-2:/usr/cx/
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>（---------------------省略-----------------------）
</span></span><span class=line><span class=cl>external.png                                  100%  230     0.2KB/s   00:00   
</span></span><span class=line><span class=cl>banner.jpg                                    100%  872     0.9KB/s   00:00   
</span></span><span class=line><span class=cl>maven-feather.png                             100% 3330     3.3KB/s   00:00   
</span></span><span class=line><span class=cl>build-by-maven-white.png                      100% 2260     2.2KB/s   00:00   
</span></span><span class=line><span class=cl>build-by-maven-black.png                      100% 2294     2.2KB/s   00:00   
</span></span><span class=line><span class=cl>bg.jpg                                        100%  486     0.5KB/s   00:00   
</span></span><span class=line><span class=cl>icon_error_sml.gif                            100% 1010     1.0KB/s   00:00   
</span></span><span class=line><span class=cl>logo_apache.jpg                               100%   33KB  32.7KB/s   00:00   
</span></span><span class=line><span class=cl>collapsed.gif                                 100%  820     0.8KB/s   00:00   
</span></span><span class=line><span class=cl>apache-maven-project-2.png                    100%   33KB  32.7KB/s   00:00   
</span></span><span class=line><span class=cl>icon_success_sml.gif                          100%  990     1.0KB/s   00:00   
</span></span><span class=line><span class=cl>icon_info_sml.gif                             100%  606     0.6KB/s   00:00   
</span></span><span class=line><span class=cl>h3.jpg                                        100%  431     0.4KB/s   00:00   
</span></span><span class=line><span class=cl>maven-logo-2.gif                              100%   26KB  25.8KB/s   00:00   
</span></span><span class=line><span class=cl>h5.jpg                                        100%  357     0.4KB/s   00:00   
</span></span><span class=line><span class=cl>newwindow.png                                 100%  220     0.2KB/s   00:00   
</span></span><span class=line><span class=cl>icon_warning_sml.gif                          100%  576     0.6KB/s   00:00   
</span></span><span class=line><span class=cl>expanded.gif                                  100%   52     0.1KB/s   00:00 
</span></span><span class=line><span class=cl>dependency-analysis.html                      100%   21KB  21.3KB/s   00:00   
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=2><li>通过下面的命令将节点1的Hadoop文件包分发到节点3中：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp -r /usr/cx/hadoop-2.7.1 root@realtime-3:/usr/cx/
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>（---------------------省略-----------------------）
</span></span><span class=line><span class=cl>external.png                                  100%  230     0.2KB/s   00:00   
</span></span><span class=line><span class=cl>banner.jpg                                    100%  872     0.9KB/s   00:00   
</span></span><span class=line><span class=cl>maven-feather.png                             100% 3330     3.3KB/s   00:00   
</span></span><span class=line><span class=cl>build-by-maven-white.png                      100% 2260     2.2KB/s   00:00   
</span></span><span class=line><span class=cl>build-by-maven-black.png                      100% 2294     2.2KB/s   00:00   
</span></span><span class=line><span class=cl>bg.jpg                                        100%  486     0.5KB/s   00:00   
</span></span><span class=line><span class=cl>icon_error_sml.gif                            100% 1010     1.0KB/s   00:00   
</span></span><span class=line><span class=cl>logo_apache.jpg                               100%   33KB  32.7KB/s   00:00   
</span></span><span class=line><span class=cl>collapsed.gif                                 100%  820     0.8KB/s   00:00   
</span></span><span class=line><span class=cl>apache-maven-project-2.png                    100%   33KB  32.7KB/s   00:00   
</span></span><span class=line><span class=cl>icon_success_sml.gif                          100%  990     1.0KB/s   00:00   
</span></span><span class=line><span class=cl>icon_info_sml.gif                             100%  606     0.6KB/s   00:00   
</span></span><span class=line><span class=cl>h3.jpg                                        100%  431     0.4KB/s   00:00   
</span></span><span class=line><span class=cl>maven-logo-2.gif                              100%   26KB  25.8KB/s   00:00   
</span></span><span class=line><span class=cl>h5.jpg                                        100%  357     0.4KB/s   00:00   
</span></span><span class=line><span class=cl>newwindow.png                                 100%  220     0.2KB/s   00:00   
</span></span><span class=line><span class=cl>icon_warning_sml.gif                          100%  576     0.6KB/s   00:00   
</span></span><span class=line><span class=cl>expanded.gif                                  100%   52     0.1KB/s   00:00   
</span></span><span class=line><span class=cl>dependency-analysis.html                      100%   21KB  21.3KB/s   00:00   
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤5-配置hadoop环境变量>步骤5. 配置Hadoop环境变量<a hidden class=anchor aria-hidden=true href=#步骤5-配置hadoop环境变量>#</a></h3><ol><li>通过下列命令使用vi编辑器编辑~/.bashrc文件：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>vi  ~/.bashrc
</span></span></code></pre></div><p>打开后的文件内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=c1># .bashrc</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># User specific aliases and functions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>alias</span> <span class=n>rm</span><span class=o>=</span><span class=s1>&#39;rm -i&#39;</span>
</span></span><span class=line><span class=cl><span class=n>alias</span> <span class=n>cp</span><span class=o>=</span><span class=s1>&#39;cp -i&#39;</span>
</span></span><span class=line><span class=cl><span class=n>alias</span> <span class=n>mv</span><span class=o>=</span><span class=s1>&#39;mv -i&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Source global definitions</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=p>[</span> <span class=o>-</span><span class=n>f</span> <span class=o>/</span><span class=n>etc</span><span class=o>/</span><span class=n>bashrc</span> <span class=p>];</span> <span class=n>then</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span> <span class=o>/</span><span class=n>etc</span><span class=o>/</span><span class=n>bashrc</span>
</span></span><span class=line><span class=cl><span class=n>fi</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>JAVA_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>jdk1</span><span class=o>.</span><span class=mf>8.0</span><span class=n>_60</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>bin</span><span class=p>:</span><span class=o>$</span><span class=n>PATH</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>CLASSPATH</span><span class=o>=.</span><span class=p>:</span><span class=o>$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>jre</span><span class=o>/</span><span class=n>lib</span><span class=o>/</span><span class=n>rt</span><span class=o>.</span><span class=n>jar</span><span class=p>:</span><span class=o>$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>jre</span><span class=o>/</span><span class=n>lib</span><span class=o>/</span><span class=n>tools</span><span class=o>.</span><span class=n>jar</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>ZK_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>zookeeper</span><span class=o>-</span><span class=mf>3.4</span><span class=o>.</span><span class=mi>6</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>PATH</span><span class=p>:</span><span class=o>$</span><span class=n>ZK_HOME</span><span class=o>/</span><span class=n>bin</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=o>----------------</span><span class=err>在此处增加内容</span><span class=o>-------------------</span><span class=p>)</span>
</span></span></code></pre></div><ol start=2><li>在~/.bashrc文件中增加以下内容：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=k>export</span> <span class=n>HADOOP_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>PATH</span><span class=p>:</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>bin</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>PATH</span><span class=p>:</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>sbin</span>
</span></span></code></pre></div><p>编辑完成后保存文件并退出vi编辑器</p><ol start=3><li>通过下面的命令将节点1的环境变量文件分发到节点2中：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp -r ~/.bashrc root@realtime-2:~/.bashrc
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# scp -r ~/.bashrc root@realtime-2:~/.bashrc
</span></span><span class=line><span class=cl>.bashrc                                       100%  502     0.5KB/s   00:00   
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=4><li>通过下面的命令将节点1的环境变量文件分发到节点3中：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>scp -r ~/.bashrc root@realtime-3:~/.bashrc
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# scp -r ~/.bashrc root@realtime-3:~/.bashrc
</span></span><span class=line><span class=cl>.bashrc                                       100%  502     0.5KB/s   00:00   
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤6-更新环境变量>步骤6. 更新环境变量<a hidden class=anchor aria-hidden=true href=#步骤6-更新环境变量>#</a></h3><ol><li>执行如下命令，更新环境变量：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>source  ~/.bashrc
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;source  ~/.bashrc&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;source  ~/.bashrc&#34;
</span></span></code></pre></div><h3 id=步骤7-验证hadoop环境变量是否配置成功>步骤7. 验证Hadoop环境变量是否配置成功<a hidden class=anchor aria-hidden=true href=#步骤7-验证hadoop环境变量是否配置成功>#</a></h3><ol><li>通过下列命令验证Hadoop环境变量是否配置成功：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hadoop
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;hadoop&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;hadoop&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>如果出现如下提示信息，则说明Hadoop安装配置成功：
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# hadoop
</span></span><span class=line><span class=cl>Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]
</span></span><span class=line><span class=cl>  CLASSNAME            run the class named CLASSNAME
</span></span><span class=line><span class=cl> or
</span></span><span class=line><span class=cl>  where COMMAND is one of:
</span></span><span class=line><span class=cl>  fs                   run a generic filesystem user client
</span></span><span class=line><span class=cl>  version              print the version
</span></span><span class=line><span class=cl>  jar &lt;jar&gt;            run a jar file
</span></span><span class=line><span class=cl>                       note: please use &#34;yarn jar&#34; to launch
</span></span><span class=line><span class=cl>                             YARN applications, not this command.
</span></span><span class=line><span class=cl>  checknative [-a|-h]  check native hadoop and compression libraries availability
</span></span><span class=line><span class=cl>  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively
</span></span><span class=line><span class=cl>  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive
</span></span><span class=line><span class=cl>  classpath            prints the class path needed to get the
</span></span><span class=line><span class=cl>  credential           interact with credential providers
</span></span><span class=line><span class=cl>                       Hadoop jar and the required libraries
</span></span><span class=line><span class=cl>  daemonlog            get/set the log level for each daemon
</span></span><span class=line><span class=cl>  trace                view and modify Hadoop tracing settings
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Most commands print help when invoked w/o parameters.
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p><em>如果没有正确输出相关信息，请检查~/.bashrc文件中的Hadoop环境变量是否配置正确，同时请确定是否使用source ~/.bashrc命令更新环境变量配置</em></p><h3 id=步骤8-格式化hdfs>步骤8. 格式化HDFS<a hidden class=anchor aria-hidden=true href=#步骤8-格式化hdfs>#</a></h3><p>通过下列命令格式化HDFS文件系统（如果格式化失败，会有相关的错误日志输出，根据输出内容进行更改即可）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hadoop namenode -format
</span></span></code></pre></div><p>命令运行后的部分显示内容如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>(-------------------省略------------------------)
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO util.GSet: Computing capacity for map NameNodeRetryCache
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO util.GSet: VM type       = 64-bit
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
</span></span><span class=line><span class=cl>18/11/30 11:07:15 INFO util.GSet: capacity      = 2^15 = 32768 entries
</span></span><span class=line><span class=cl>18/11/30 11:07:16 INFO namenode.FSImage: Allocated new BlockPoolId: BP-348760827-10.1.1.4-1543547236332
</span></span><span class=line><span class=cl>18/11/30 11:07:16 INFO common.Storage: Storage directory /hdfs/namenode has been successfully formatted.
</span></span><span class=line><span class=cl>18/11/30 11:07:16 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0
</span></span><span class=line><span class=cl>18/11/30 11:07:16 INFO util.ExitUtil: Exiting with status 0
</span></span><span class=line><span class=cl>18/11/30 11:07:16 INFO namenode.NameNode: SHUTDOWN_MSG:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>/************************************************************
</span></span><span class=line><span class=cl>SHUTDOWN_MSG: Shutting down NameNode at realtime-1/10.1.1.4
</span></span><span class=line><span class=cl>************************************************************/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h3 id=步骤9-格式化zkfc元数据>步骤9. 格式化zkfc元数据<a hidden class=anchor aria-hidden=true href=#步骤9-格式化zkfc元数据>#</a></h3><p>通过下面的命令格式化DFSZKFailoverController(ZKFC)元数据（在一个节点中进行处理即可）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hdfs zkfc -formatZK
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>（---------------省略------------------）
</span></span><span class=line><span class=cl>tString=realtime-1:2181,realtime-2:2181,realtime-3:2181 sessionTimeout=5000 watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@10e31a9a
</span></span><span class=line><span class=cl>18/11/30 11:37:46 INFO zookeeper.ClientCnxn: Opening socket connection to server realtime-2/10.1.1.3:2181. Will not attempt to authenticate using SASL (unknown error)
</span></span><span class=line><span class=cl>18/11/30 11:37:47 INFO zookeeper.ClientCnxn: Socket connection established to realtime-2/10.1.1.3:2181, initiating session
</span></span><span class=line><span class=cl>18/11/30 11:37:47 INFO zookeeper.ClientCnxn: Session establishment complete on server realtime-2/10.1.1.3:2181, sessionid = 0x2675e9a37a90000, negotiated timeout = 5000
</span></span><span class=line><span class=cl>18/11/30 11:37:47 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/HDFScluster in ZK.
</span></span><span class=line><span class=cl>18/11/30 11:37:47 INFO ha.ActiveStandbyElector: Session connected.
</span></span><span class=line><span class=cl>18/11/30 11:37:47 INFO zookeeper.ZooKeeper: Session: 0x2675e9a37a90000 closed
</span></span><span class=line><span class=cl>18/11/30 11:37:47 INFO zookeeper.ClientCnxn: EventThread shut down
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><h2 id=9-hadoop集群启动运行>9 Hadoop集群启动运行<a hidden class=anchor aria-hidden=true href=#9-hadoop集群启动运行>#</a></h2><p>我们在节点1进行下列操作，在节点1中通过ssh远程登录到节点2和节点3中，实现命令的分发与运行</p><h3 id=步骤1-启动hdfs相关服务>步骤1. 启动HDFS相关服务<a hidden class=anchor aria-hidden=true href=#步骤1-启动hdfs相关服务>#</a></h3><ol><li>通过下面的命令可以启动HDFS相关服务：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>start-dfs.sh
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># start-dfs.sh</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>11</span><span class=p>:</span><span class=mi>55</span><span class=p>:</span><span class=mi>51</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=n>Starting</span> <span class=n>namenodes</span> <span class=n>on</span> <span class=p>[</span><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span> <span class=n>starting</span> <span class=n>namenode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>namenode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>2.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span> <span class=n>starting</span> <span class=n>namenode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>namenode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>1.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span> <span class=n>starting</span> <span class=n>datanode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>datanode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>1.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span> <span class=n>starting</span> <span class=n>datanode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>datanode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>2.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>3</span><span class=p>:</span> <span class=n>starting</span> <span class=n>datanode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>datanode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>3.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>Starting</span> <span class=n>journal</span> <span class=n>nodes</span> <span class=p>[</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>3</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span> <span class=n>starting</span> <span class=n>journalnode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>journalnode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>1.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span> <span class=n>starting</span> <span class=n>journalnode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>journalnode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>2.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>3</span><span class=p>:</span> <span class=n>starting</span> <span class=n>journalnode</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>journalnode</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>3.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>11</span><span class=p>:</span><span class=mi>56</span><span class=p>:</span><span class=mi>11</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=n>Starting</span> <span class=n>ZK</span> <span class=n>Failover</span> <span class=n>Controllers</span> <span class=n>on</span> <span class=n>NN</span> <span class=n>hosts</span> <span class=p>[</span><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span> <span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span> <span class=n>starting</span> <span class=n>zkfc</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>zkfc</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>2.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span> <span class=n>starting</span> <span class=n>zkfc</span><span class=p>,</span> <span class=n>logging</span> <span class=n>to</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>cx</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.7</span><span class=o>.</span><span class=mi>1</span><span class=o>/</span><span class=n>logs</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=n>root</span><span class=o>-</span><span class=n>zkfc</span><span class=o>-</span><span class=n>realtime</span><span class=o>-</span><span class=mf>1.</span><span class=n>out</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><ol start=2><li>通过下面的命令查看节点1中对应的相关服务：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>jps
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;jps&#34;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-3 &#34;jps&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# jps
</span></span><span class=line><span class=cl>10033 ResourceManager
</span></span><span class=line><span class=cl>9427 DataNode
</span></span><span class=line><span class=cl>9315 NameNode
</span></span><span class=line><span class=cl>2597 QuorumPeerMain
</span></span><span class=line><span class=cl>10457 Jps
</span></span><span class=line><span class=cl>9625 JournalNode
</span></span><span class=line><span class=cl>9818 DFSZKFailoverController
</span></span><span class=line><span class=cl>10140 NodeManager
</span></span><span class=line><span class=cl>1743 VmServer.jar
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>通过下面的命令在节点2中启动ResourceManager进程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;yarn-daemon.sh start resourcemanager&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-2 &#34;yarn-daemon.sh start resourcemanager&#34;
</span></span><span class=line><span class=cl>starting resourcemanager, logging to /usr/cx/hadoop-2.7.1/logs/yarn-root-resourcemanager-realtime-2.out
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>通过下面的命令查看节点2中对应的相关服务：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-2 &#34;jps&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-2 &#34;jps&#34;
</span></span><span class=line><span class=cl>5792 DataNode
</span></span><span class=line><span class=cl>6164 NameNode
</span></span><span class=line><span class=cl>1703 VmServer.jar
</span></span><span class=line><span class=cl>6779 ResourceManager
</span></span><span class=line><span class=cl>6428 NodeManager
</span></span><span class=line><span class=cl>5981 DFSZKFailoverController
</span></span><span class=line><span class=cl>6846 Jps
</span></span><span class=line><span class=cl>2686 QuorumPeerMain
</span></span><span class=line><span class=cl>5887 JournalNode
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>由返回结果可以看出，此时在节点2中已经成功启动了ResourceManager进程</p><h2 id=10-hadoop-高可用性测试>10 Hadoop 高可用性测试<a hidden class=anchor aria-hidden=true href=#10-hadoop-高可用性测试>#</a></h2><p>笔者在写作过程中是在节点1中进行下面的操作，同学们可以在任意节点中进行下面的操作，所实现的效果是一致的</p><h3 id=步骤1-nodemanager状态查看>步骤1. NodeManager状态查看<a hidden class=anchor aria-hidden=true href=#步骤1-nodemanager状态查看>#</a></h3><p>由于设置了2个NameNode，因此必然会有一个处于Active状态，一个处于StandBy状态，至于具体哪个节点处于Active状态，需要根据实际情况确定，并不是千篇一律的。</p><ol><li>当Hadoop成功启动后，我们打开浏览器，输入网址http://realtime-1:50070便可以访问HDFS的Web管理页面（此时可以看到realtime-1节点是处于active状态的）：</li></ol><p><div class=post-img-view><a data-fancybox=gallery href=https://qiniu.waite.wang/pab7rz.png><img src=https://qiniu.waite.wang/pab7rz.png alt=pab7rz></a></div></p><ol start=2><li>输入网址http://realtime-2:50070依然可以访问HDFS的Web管理页面（此时可以看到realtime-2节点是处于standby状态的）：</li></ol><p><div class=post-img-view><a data-fancybox=gallery href=https://qiniu.waite.wang/noepa4.png><img src=https://qiniu.waite.wang/noepa4.png alt=noepa4></a></div></p><h3 id=步骤2-resourcemanager状态查看>步骤2. ResourceManager状态查看<a hidden class=anchor aria-hidden=true href=#步骤2-resourcemanager状态查看>#</a></h3><p>由于设置了2个ResourceManager，因此必然会有一个处于Active状态，一个处于StandBy状态，至于具体哪个节点处于Active状态，需要根据实际情况确定，并不是千篇一律的。</p><ol><li>在终端模拟器中，通过下面的命令可以查看逻辑ID为rm1（实际映射的节点为realtime-1）的节点对应的ResourceManager状态：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>yarn rmadmin -getServiceState rm1
</span></span></code></pre></div><p>命令运行后的返回结果如下所示（可见当前节点是active状态）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># yarn rmadmin -getServiceState rm1</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>35</span><span class=p>:</span><span class=mi>11</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=n>active</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><ol start=2><li>在终端模拟器中，通过下面的命令可以查看逻辑ID为rm2（实际映射的节点为realtime-2）的节点对应的ResourceManager状态：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>yarn rmadmin -getServiceState rm2
</span></span></code></pre></div><p>命令运行后的返回结果如下所示（可见当前节点是standby状态）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># yarn rmadmin -getServiceState rm2</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>35</span><span class=p>:</span><span class=mi>44</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=n>standby</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><h3 id=步骤3-hdfs高可用测试>步骤3. HDFS高可用测试<a hidden class=anchor aria-hidden=true href=#步骤3-hdfs高可用测试>#</a></h3><ol><li>通过下面的命令在HDFS中创建测试文件夹/test：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hadoop fs -mkdir /test
</span></span></code></pre></div><ol start=2><li>通过下面的命令查看HDFS中创建的测试文件夹/test：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hadoop fs -ls /
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># hadoop fs -ls /</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>40</span><span class=p>:</span><span class=mi>12</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=n>Found</span> <span class=mi>1</span> <span class=n>items</span>
</span></span><span class=line><span class=cl><span class=n>drwxr</span><span class=o>-</span><span class=n>xr</span><span class=o>-</span><span class=n>x</span>   <span class=o>-</span> <span class=n>root</span> <span class=n>supergroup</span>          <span class=mi>0</span> <span class=mi>2018</span><span class=o>-</span><span class=mi>11</span><span class=o>-</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>39</span> <span class=o>/</span><span class=n>test</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><p>由返回结果可以看出，此时依然可以成功查询HDFS文件信息</p><p>打开浏览器，输入网址http://realtime-2:50070访问HDFS的Web管理页面，此时可以看到realtime-2节点已经成功接替成为NameNode并处于active状态（同学们需要根据实际情况来确定）：</p><p><div class=post-img-view><a data-fancybox=gallery href=https://qiniu.waite.wang/lu3bmj.png><img src=https://qiniu.waite.wang/lu3bmj.png alt=lu3bmj></a></div></p><h3 id=步骤4-yarn高可用测试>步骤4. YARN高可用测试<a hidden class=anchor aria-hidden=true href=#步骤4-yarn高可用测试>#</a></h3><ol><li>通过下面的命令，使用Hadoop自带的案例测试MapReduce应用程序的运行：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>11</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>15</span> <span class=n>INFO</span> <span class=n>input</span><span class=o>.</span><span class=n>FileInputFormat</span><span class=p>:</span> <span class=n>Total</span> <span class=n>input</span> <span class=n>paths</span> <span class=n>to</span> <span class=n>process</span> <span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>15</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>JobSubmitter</span><span class=p>:</span> <span class=n>number</span> <span class=n>of</span> <span class=n>splits</span><span class=p>:</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>15</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>JobSubmitter</span><span class=p>:</span> <span class=n>Submitting</span> <span class=n>tokens</span> <span class=k>for</span> <span class=n>job</span><span class=p>:</span> <span class=n>job_1543557487449_0001</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>16</span> <span class=n>INFO</span> <span class=n>impl</span><span class=o>.</span><span class=n>YarnClientImpl</span><span class=p>:</span> <span class=n>Submitted</span> <span class=n>application</span> <span class=n>application_1543557487449_0001</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>16</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>The</span> <span class=n>url</span> <span class=n>to</span> <span class=n>track</span> <span class=n>the</span> <span class=n>job</span><span class=p>:</span> <span class=n>http</span><span class=p>:</span><span class=o>//</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span><span class=p>:</span><span class=mi>8089</span><span class=o>/</span><span class=n>proxy</span><span class=o>/</span><span class=n>application_1543557487449_0001</span><span class=o>/</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>16</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Running</span> <span class=n>job</span><span class=p>:</span> <span class=n>job_1543557487449_0001</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>26</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Job</span> <span class=n>job_1543557487449_0001</span> <span class=n>running</span> <span class=ow>in</span> <span class=n>uber</span> <span class=n>mode</span> <span class=p>:</span> <span class=bp>false</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>26</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span>  <span class=n>map</span> <span class=mi>0</span><span class=o>%</span> <span class=n>reduce</span> <span class=mi>0</span><span class=o>%</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>37</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span>  <span class=n>map</span> <span class=mi>0</span><span class=o>%</span> <span class=n>reduce</span> <span class=mi>100</span><span class=o>%</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>38</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Job</span> <span class=n>job_1543557487449_0001</span> <span class=n>completed</span> <span class=n>successfully</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>39</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Counters</span><span class=p>:</span> <span class=mi>38</span>
</span></span><span class=line><span class=cl>   <span class=ne>File</span> <span class=n>System</span> <span class=n>Counters</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>read</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>written</span><span class=o>=</span><span class=mi>119357</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>large</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>write</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>read</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>written</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>3</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>large</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>write</span> <span class=n>operations</span><span class=o>=</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>   <span class=n>Job</span> <span class=n>Counters</span>
</span></span><span class=line><span class=cl>        <span class=n>Launched</span> <span class=n>reduce</span> <span class=n>tasks</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>time</span> <span class=n>spent</span> <span class=n>by</span> <span class=n>all</span> <span class=n>maps</span> <span class=ow>in</span> <span class=n>occupied</span> <span class=n>slots</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>time</span> <span class=n>spent</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduces</span> <span class=ow>in</span> <span class=n>occupied</span> <span class=n>slots</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>227232</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>time</span> <span class=n>spent</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduce</span> <span class=n>tasks</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>7101</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>vcore</span><span class=o>-</span><span class=n>seconds</span> <span class=n>taken</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduce</span> <span class=n>tasks</span><span class=o>=</span><span class=mi>7101</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>megabyte</span><span class=o>-</span><span class=n>seconds</span> <span class=n>taken</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduce</span> <span class=n>tasks</span><span class=o>=</span><span class=mi>7271424</span>
</span></span><span class=line><span class=cl>   <span class=n>Map</span><span class=o>-</span><span class=n>Reduce</span> <span class=n>Framework</span>
</span></span><span class=line><span class=cl>        <span class=n>Combine</span> <span class=n>input</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Combine</span> <span class=n>output</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>input</span> <span class=n>groups</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>shuffle</span> <span class=n>bytes</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>input</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>output</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Spilled</span> <span class=n>Records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Shuffled</span> <span class=n>Maps</span> <span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Failed</span> <span class=n>Shuffles</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Merged</span> <span class=n>Map</span> <span class=n>outputs</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>GC</span> <span class=n>time</span> <span class=n>elapsed</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>67</span>
</span></span><span class=line><span class=cl>        <span class=n>CPU</span> <span class=n>time</span> <span class=n>spent</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>290</span>
</span></span><span class=line><span class=cl>        <span class=n>Physical</span> <span class=n>memory</span> <span class=p>(</span><span class=n>bytes</span><span class=p>)</span> <span class=n>snapshot</span><span class=o>=</span><span class=mi>94629888</span>
</span></span><span class=line><span class=cl>        <span class=n>Virtual</span> <span class=n>memory</span> <span class=p>(</span><span class=n>bytes</span><span class=p>)</span> <span class=n>snapshot</span><span class=o>=</span><span class=mi>2064699392</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>committed</span> <span class=n>heap</span> <span class=n>usage</span> <span class=p>(</span><span class=n>bytes</span><span class=p>)</span><span class=o>=</span><span class=mi>30474240</span>
</span></span><span class=line><span class=cl>   <span class=n>Shuffle</span> <span class=n>Errors</span>
</span></span><span class=line><span class=cl>        <span class=n>BAD_ID</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>CONNECTION</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>IO_ERROR</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>WRONG_LENGTH</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>WRONG_MAP</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>WRONG_REDUCE</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>   <span class=ne>File</span> <span class=n>Output</span> <span class=n>Format</span> <span class=n>Counters</span>
</span></span><span class=line><span class=cl>        <span class=n>Bytes</span> <span class=n>Written</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><ol start=2><li>通过下面的命令停止Active状态节点对应的ResourceManager进程（笔者写作过程中对应的为realtime-1节点，同学们需要根据实际情况来确定）</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-1 &#34;yarn-daemon.sh stop resourcemanager&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-1 &#34;yarn-daemon.sh stop resourcemanager&#34;
</span></span><span class=line><span class=cl>stopping resourcemanager
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><ol start=3><li>通过下面的命令查看对应节点的进程信息：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ssh realtime-1 &#34;jps&#34;
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@realtime-1 ~]# ssh realtime-1 &#34;jps&#34;
</span></span><span class=line><span class=cl>9427 DataNode
</span></span><span class=line><span class=cl>2597 QuorumPeerMain
</span></span><span class=line><span class=cl>9625 JournalNode
</span></span><span class=line><span class=cl>9818 DFSZKFailoverController
</span></span><span class=line><span class=cl>10140 NodeManager
</span></span><span class=line><span class=cl>11885 Jps
</span></span><span class=line><span class=cl>1743 VmServer.jar
</span></span><span class=line><span class=cl>[root@realtime-1 ~]#
</span></span></code></pre></div><p>由返回结果可以看出，ResourceManager进程已经被停止</p><ol start=4><li>通过下面的命令，再次使用Hadoop自带的案例测试MapReduce应用程序的运行：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output1
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># hadoop jar /usr/cx/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /test /output1</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>29</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>31</span> <span class=n>INFO</span> <span class=n>client</span><span class=o>.</span><span class=n>ConfiguredRMFailoverProxyProvider</span><span class=p>:</span> <span class=n>Failing</span> <span class=n>over</span> <span class=n>to</span> <span class=n>rm2</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>32</span> <span class=n>INFO</span> <span class=n>input</span><span class=o>.</span><span class=n>FileInputFormat</span><span class=p>:</span> <span class=n>Total</span> <span class=n>input</span> <span class=n>paths</span> <span class=n>to</span> <span class=n>process</span> <span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>32</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>JobSubmitter</span><span class=p>:</span> <span class=n>number</span> <span class=n>of</span> <span class=n>splits</span><span class=p>:</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>32</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>JobSubmitter</span><span class=p>:</span> <span class=n>Submitting</span> <span class=n>tokens</span> <span class=k>for</span> <span class=n>job</span><span class=p>:</span> <span class=n>job_1543567750404_0001</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>33</span> <span class=n>INFO</span> <span class=n>impl</span><span class=o>.</span><span class=n>YarnClientImpl</span><span class=p>:</span> <span class=n>Submitted</span> <span class=n>application</span> <span class=n>application_1543567750404_0001</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>33</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>The</span> <span class=n>url</span> <span class=n>to</span> <span class=n>track</span> <span class=n>the</span> <span class=n>job</span><span class=p>:</span> <span class=n>http</span><span class=p>:</span><span class=o>//</span><span class=n>realtime</span><span class=o>-</span><span class=mi>2</span><span class=p>:</span><span class=mi>8089</span><span class=o>/</span><span class=n>proxy</span><span class=o>/</span><span class=n>application_1543567750404_0001</span><span class=o>/</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>33</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Running</span> <span class=n>job</span><span class=p>:</span> <span class=n>job_1543567750404_0001</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>45</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Job</span> <span class=n>job_1543567750404_0001</span> <span class=n>running</span> <span class=ow>in</span> <span class=n>uber</span> <span class=n>mode</span> <span class=p>:</span> <span class=bp>false</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>45</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span>  <span class=n>map</span> <span class=mi>0</span><span class=o>%</span> <span class=n>reduce</span> <span class=mi>0</span><span class=o>%</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>53</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span>  <span class=n>map</span> <span class=mi>0</span><span class=o>%</span> <span class=n>reduce</span> <span class=mi>100</span><span class=o>%</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>54</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Job</span> <span class=n>job_1543567750404_0001</span> <span class=n>completed</span> <span class=n>successfully</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>50</span><span class=p>:</span><span class=mi>54</span> <span class=n>INFO</span> <span class=n>mapreduce</span><span class=o>.</span><span class=n>Job</span><span class=p>:</span> <span class=n>Counters</span><span class=p>:</span> <span class=mi>38</span>
</span></span><span class=line><span class=cl>   <span class=ne>File</span> <span class=n>System</span> <span class=n>Counters</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>read</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>written</span><span class=o>=</span><span class=mi>119358</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>large</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>FILE</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>write</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>read</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>bytes</span> <span class=n>written</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>3</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>large</span> <span class=n>read</span> <span class=n>operations</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>HDFS</span><span class=p>:</span> <span class=n>Number</span> <span class=n>of</span> <span class=n>write</span> <span class=n>operations</span><span class=o>=</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>   <span class=n>Job</span> <span class=n>Counters</span>
</span></span><span class=line><span class=cl>        <span class=n>Launched</span> <span class=n>reduce</span> <span class=n>tasks</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>time</span> <span class=n>spent</span> <span class=n>by</span> <span class=n>all</span> <span class=n>maps</span> <span class=ow>in</span> <span class=n>occupied</span> <span class=n>slots</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>time</span> <span class=n>spent</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduces</span> <span class=ow>in</span> <span class=n>occupied</span> <span class=n>slots</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>147936</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>time</span> <span class=n>spent</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduce</span> <span class=n>tasks</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>4623</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>vcore</span><span class=o>-</span><span class=n>seconds</span> <span class=n>taken</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduce</span> <span class=n>tasks</span><span class=o>=</span><span class=mi>4623</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>megabyte</span><span class=o>-</span><span class=n>seconds</span> <span class=n>taken</span> <span class=n>by</span> <span class=n>all</span> <span class=n>reduce</span> <span class=n>tasks</span><span class=o>=</span><span class=mi>4733952</span>
</span></span><span class=line><span class=cl>   <span class=n>Map</span><span class=o>-</span><span class=n>Reduce</span> <span class=n>Framework</span>
</span></span><span class=line><span class=cl>        <span class=n>Combine</span> <span class=n>input</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Combine</span> <span class=n>output</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>input</span> <span class=n>groups</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>shuffle</span> <span class=n>bytes</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>input</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Reduce</span> <span class=n>output</span> <span class=n>records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Spilled</span> <span class=n>Records</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Shuffled</span> <span class=n>Maps</span> <span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Failed</span> <span class=n>Shuffles</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>Merged</span> <span class=n>Map</span> <span class=n>outputs</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>GC</span> <span class=n>time</span> <span class=n>elapsed</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>81</span>
</span></span><span class=line><span class=cl>        <span class=n>CPU</span> <span class=n>time</span> <span class=n>spent</span> <span class=p>(</span><span class=n>ms</span><span class=p>)</span><span class=o>=</span><span class=mi>280</span>
</span></span><span class=line><span class=cl>        <span class=n>Physical</span> <span class=n>memory</span> <span class=p>(</span><span class=n>bytes</span><span class=p>)</span> <span class=n>snapshot</span><span class=o>=</span><span class=mi>94146560</span>
</span></span><span class=line><span class=cl>        <span class=n>Virtual</span> <span class=n>memory</span> <span class=p>(</span><span class=n>bytes</span><span class=p>)</span> <span class=n>snapshot</span><span class=o>=</span><span class=mi>2064695296</span>
</span></span><span class=line><span class=cl>        <span class=n>Total</span> <span class=n>committed</span> <span class=n>heap</span> <span class=n>usage</span> <span class=p>(</span><span class=n>bytes</span><span class=p>)</span><span class=o>=</span><span class=mi>30474240</span>
</span></span><span class=line><span class=cl>   <span class=n>Shuffle</span> <span class=n>Errors</span>
</span></span><span class=line><span class=cl>        <span class=n>BAD_ID</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>CONNECTION</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>IO_ERROR</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>WRONG_LENGTH</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>WRONG_MAP</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>WRONG_REDUCE</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl>   <span class=ne>File</span> <span class=n>Output</span> <span class=n>Format</span> <span class=n>Counters</span>
</span></span><span class=line><span class=cl>        <span class=n>Bytes</span> <span class=n>Written</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><p>由返回结果可以看出，此时YARN依然可以可靠的实现任务的调度</p><ol start=5><li>在终端模拟器中，通过下面的命令可以查看逻辑ID为rm2（实际映射的节点为realtime-2）的节点对应的ResourceManager状态（同学们需要根据实际情况来确定）：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>yarn rmadmin -getServiceState rm2
</span></span></code></pre></div><p>命令运行后的返回结果如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1># yarn rmadmin -getServiceState rm2</span>
</span></span><span class=line><span class=cl><span class=mi>18</span><span class=o>/</span><span class=mi>11</span><span class=o>/</span><span class=mi>30</span> <span class=mi>16</span><span class=p>:</span><span class=mi>51</span><span class=p>:</span><span class=mi>39</span> <span class=n>WARN</span> <span class=n>util</span><span class=o>.</span><span class=n>NativeCodeLoader</span><span class=p>:</span> <span class=n>Unable</span> <span class=n>to</span> <span class=nb>load</span> <span class=n>native</span><span class=o>-</span><span class=n>hadoop</span> <span class=n>library</span> <span class=k>for</span> <span class=n>your</span> <span class=n>platform</span><span class=o>...</span> <span class=n>using</span> <span class=n>builtin</span><span class=o>-</span><span class=n>java</span> <span class=n>classes</span> <span class=n>where</span> <span class=n>applicable</span>
</span></span><span class=line><span class=cl><span class=n>active</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>realtime</span><span class=o>-</span><span class=mi>1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></div><p>由返回结果可以看出，当前节点已经自动成功接替变成了active状态</p><p><a href=http://49.234.55.187:8090/archives/hadoop%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E4%B8%8E%E9%85%8D%E7%BD%AE target=_blank></a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://waite.wang/tags/hadoop/>Hadoop</a></li></ul><nav class=paginav><a class=prev href=https://waite.wang/posts/bigdata/hadoop-install-and-config/><span class=title>« 上一页</span><br><span>hadoop的安装与配置</span>
</a><a class=next href=https://waite.wang/posts/vue/vue2-core-learn/><span class=title>下一页 »</span><br><span>Vue2 核心语法</span></a></nav></footer><script src=https://utteranc.es/client.js repo=Waite0603/HugoBlog issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span><a href=https://beian.miit.gov.cn/ target=_blank rel="noopener noreferrer">粤 ICP 备 2022028437 号</a></span><br><span>Copyright &copy; 2018 - 2025 By <a href=https://waite.wang/>Waite</a>, All Rights
Reserved.</span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script src=/js/jquery-3.5.1.min.js></script><link rel=stylesheet href=/css/jquery.fancybox.min.css><script src=/js/jquery.fancybox.min.js></script></body></html>